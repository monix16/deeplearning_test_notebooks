{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"cntk\"\nos.environ[\u0027CNTK_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda-8.0/lib64,dnn.include_path\u003d/usr/local/cuda-8.0/include/\u0027",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 24, 2018 10:28:25 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516357425830_-1654927244",
      "id": "20180119-102345_1169506047_q_WS9XDM1E8C1516598377",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 19, 2018 10:23:45 AM",
      "dateStarted": "Jan 24, 2018 10:28:25 AM",
      "dateFinished": "Jan 24, 2018 10:28:25 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to CNTK\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 24, 2018 10:28:25 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516357432932_-1768412846",
      "id": "20180119-102352_1430423204_q_WS9XDM1E8C1516598377",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "cntk\n"
      },
      "dateCreated": "Jan 19, 2018 10:23:52 AM",
      "dateStarted": "Jan 24, 2018 10:28:25 AM",
      "dateFinished": "Jan 24, 2018 10:28:25 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from __future__ import print_function\nfrom functools import reduce\nimport re\nimport tarfile\n\nimport numpy as np\n\nfrom keras.utils.data_utils import get_file\nfrom keras.layers.embeddings import Embedding\nfrom keras import layers\nfrom keras.layers import recurrent\nfrom keras.models import Model\nfrom keras.preprocessing.sequence import pad_sequences\n\n\ndef tokenize(sent):\n    \u0027\u0027\u0027Return the tokens of a sentence including punctuation.\n    \u003e\u003e\u003e tokenize(\u0027Bob dropped the apple. Where is the apple?\u0027)\n    [\u0027Bob\u0027, \u0027dropped\u0027, \u0027the\u0027, \u0027apple\u0027, \u0027.\u0027, \u0027Where\u0027, \u0027is\u0027, \u0027the\u0027, \u0027apple\u0027, \u0027?\u0027]\n    \u0027\u0027\u0027\n    return [x.strip() for x in re.split(\u0027(\\W+)?\u0027, sent) if x.strip()]\n\n\ndef parse_stories(lines, only_supporting\u003dFalse):\n    \u0027\u0027\u0027Parse stories provided in the bAbi tasks format\n    If only_supporting is true,\n    only the sentences that support the answer are kept.\n    \u0027\u0027\u0027\n    data \u003d []\n    story \u003d []\n    for line in lines:\n        line \u003d line.decode(\u0027utf-8\u0027).strip()\n        nid, line \u003d line.split(\u0027 \u0027, 1)\n        nid \u003d int(nid)\n        if nid \u003d\u003d 1:\n            story \u003d []\n        if \u0027\\t\u0027 in line:\n            q, a, supporting \u003d line.split(\u0027\\t\u0027)\n            q \u003d tokenize(q)\n            substory \u003d None\n            if only_supporting:\n                # Only select the related substory\n                supporting \u003d map(int, supporting.split())\n                substory \u003d [story[i - 1] for i in supporting]\n            else:\n                # Provide all the substories\n                substory \u003d [x for x in story if x]\n            data.append((substory, q, a))\n            story.append(\u0027\u0027)\n        else:\n            sent \u003d tokenize(line)\n            story.append(sent)\n    return data\n\n\ndef get_stories(f, only_supporting\u003dFalse, max_length\u003dNone):\n    \u0027\u0027\u0027Given a file name, read the file, retrieve the stories,\n    and then convert the sentences into a single story.\n    If max_length is supplied,\n    any stories longer than max_length tokens will be discarded.\n    \u0027\u0027\u0027\n    data \u003d parse_stories(f.readlines(), only_supporting\u003donly_supporting)\n    flatten \u003d lambda data: reduce(lambda x, y: x + y, data)\n    data \u003d [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) \u003c max_length]\n    return data\n\n\ndef vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n    xs \u003d []\n    xqs \u003d []\n    ys \u003d []\n    for story, query, answer in data:\n        x \u003d [word_idx[w] for w in story]\n        xq \u003d [word_idx[w] for w in query]\n        # let\u0027s not forget that index 0 is reserved\n        y \u003d np.zeros(len(word_idx) + 1)\n        y[word_idx[answer]] \u003d 1\n        xs.append(x)\n        xqs.append(xq)\n        ys.append(y)\n    return pad_sequences(xs, maxlen\u003dstory_maxlen), pad_sequences(xqs, maxlen\u003dquery_maxlen), np.array(ys)\n\nRNN \u003d recurrent.LSTM\nEMBED_HIDDEN_SIZE \u003d 50\nSENT_HIDDEN_SIZE \u003d 100\nQUERY_HIDDEN_SIZE \u003d 100\nBATCH_SIZE \u003d 32\nEPOCHS \u003d 5\nprint(\u0027RNN / Embed / Sent / Query \u003d {}, {}, {}, {}\u0027.format(RNN,\n                                                           EMBED_HIDDEN_SIZE,\n                                                           SENT_HIDDEN_SIZE,\n                                                           QUERY_HIDDEN_SIZE))\n\ntry:\n    path \u003d get_file(\u0027babi-tasks-v1-2.tar.gz\u0027, origin\u003d\u0027https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\u0027)\nexcept:\n    print(\u0027Error downloading dataset, please download it manually:\\n\u0027\n          \u0027$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n\u0027\n          \u0027$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz\u0027)\n    raise\ntar \u003d tarfile.open(path)\n# Default QA1 with 1000 samples\n# challenge \u003d \u0027tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt\u0027\n# QA1 with 10,000 samples\n# challenge \u003d \u0027tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt\u0027\n# QA2 with 1000 samples\nchallenge \u003d \u0027tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt\u0027\n# QA2 with 10,000 samples\n# challenge \u003d \u0027tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt\u0027\ntrain \u003d get_stories(tar.extractfile(challenge.format(\u0027train\u0027)))\ntest \u003d get_stories(tar.extractfile(challenge.format(\u0027test\u0027)))\n\nvocab \u003d set()\nfor story, q, answer in train + test:\n    vocab |\u003d set(story + q + [answer])\nvocab \u003d sorted(vocab)\n\n# Reserve 0 for masking via pad_sequences\nvocab_size \u003d len(vocab) + 1\nword_idx \u003d dict((c, i + 1) for i, c in enumerate(vocab))\nstory_maxlen \u003d max(map(len, (x for x, _, _ in train + test)))\nquery_maxlen \u003d max(map(len, (x for _, x, _ in train + test)))\n\nx, xq, y \u003d vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\ntx, txq, ty \u003d vectorize_stories(test, word_idx, story_maxlen, query_maxlen)\n\nprint(\u0027vocab \u003d {}\u0027.format(vocab))\nprint(\u0027x.shape \u003d {}\u0027.format(x.shape))\nprint(\u0027xq.shape \u003d {}\u0027.format(xq.shape))\nprint(\u0027y.shape \u003d {}\u0027.format(y.shape))\nprint(\u0027story_maxlen, query_maxlen \u003d {}, {}\u0027.format(story_maxlen, query_maxlen))\n\nprint(\u0027Build model...\u0027)\n\nsentence \u003d layers.Input(shape\u003d(story_maxlen,), dtype\u003d\u0027int32\u0027)\nencoded_sentence \u003d layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\nencoded_sentence \u003d layers.Dropout(0.3)(encoded_sentence)\n\nquestion \u003d layers.Input(shape\u003d(query_maxlen,), dtype\u003d\u0027int32\u0027)\nencoded_question \u003d layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\nencoded_question \u003d layers.Dropout(0.3)(encoded_question)\nencoded_question \u003d RNN(EMBED_HIDDEN_SIZE)(encoded_question)\nencoded_question \u003d layers.RepeatVector(story_maxlen)(encoded_question)\n\nmerged \u003d layers.add([encoded_sentence, encoded_question])\nmerged \u003d RNN(EMBED_HIDDEN_SIZE)(merged)\nmerged \u003d layers.Dropout(0.3)(merged)\npreds \u003d layers.Dense(vocab_size, activation\u003d\u0027softmax\u0027)(merged)\n\nmodel \u003d Model([sentence, question], preds)\nmodel.compile(optimizer\u003d\u0027adam\u0027,\n              loss\u003d\u0027categorical_crossentropy\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\n\nprint(\u0027Training\u0027)\nmodel.fit([x, xq], y,\n          batch_size\u003dBATCH_SIZE,\n          epochs\u003dEPOCHS,\n          validation_split\u003d0.05)\nloss, acc \u003d model.evaluate([tx, txq], ty,\n                           batch_size\u003dBATCH_SIZE)\nprint(\u0027Test loss / test accuracy \u003d {:.4f} / {:.4f}\u0027.format(loss, acc))",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 24, 2018 10:28:25 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516019341729_-919397811",
      "id": "20180115-122901_1736191046_q_WS9XDM1E8C1516598377",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "RNN / Embed / Sent / Query \u003d \u003cclass \u0027keras.layers.recurrent.LSTM\u0027\u003e, 50, 100, 100\nvocab \u003d [\u0027.\u0027, \u0027?\u0027, \u0027Daniel\u0027, \u0027John\u0027, \u0027Mary\u0027, \u0027Sandra\u0027, \u0027Where\u0027, \u0027apple\u0027, \u0027back\u0027, \u0027bathroom\u0027, \u0027bedroom\u0027, \u0027discarded\u0027, \u0027down\u0027, \u0027dropped\u0027, \u0027football\u0027, \u0027garden\u0027, \u0027got\u0027, \u0027grabbed\u0027, \u0027hallway\u0027, \u0027is\u0027, \u0027journeyed\u0027, \u0027kitchen\u0027, \u0027left\u0027, \u0027milk\u0027, \u0027moved\u0027, \u0027office\u0027, \u0027picked\u0027, \u0027put\u0027, \u0027the\u0027, \u0027there\u0027, \u0027to\u0027, \u0027took\u0027, \u0027travelled\u0027, \u0027up\u0027, \u0027went\u0027]\nx.shape \u003d (1000, 552)\nxq.shape \u003d (1000, 5)\ny.shape \u003d (1000, 36)\nstory_maxlen, query_maxlen \u003d 552, 5\nBuild model...\nTraining\nTrain on 950 samples, validate on 50 samples\nEpoch 1/5\n/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input33336\") expects \"\u003cclass \u0027numpy.float32\u0027\u003e\". Please convert your data beforehand to speed up training.\n  (sample.dtype, var.uid, str(var.dtype)))\n\n 32/950 [\u003e.............................] - ETA: 28s - loss: 3.5856 - acc: 0.0312\n\n 64/950 [\u003d\u003e............................] - ETA: 19s - loss: 3.5826 - acc: 0.0312\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 16s - loss: 3.5789 - acc: 0.0521\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 14s - loss: 3.5752 - acc: 0.1016\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 13s - loss: 3.5732 - acc: 0.1187\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 12s - loss: 3.5705 - acc: 0.1250\n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 11s - loss: 3.5667 - acc: 0.1250\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 10s - loss: 3.5637 - acc: 0.1250\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 9s - loss: 3.5603 - acc: 0.1285 \n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 9s - loss: 3.5555 - acc: 0.1219\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 8s - loss: 3.5509 - acc: 0.1193\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 8s - loss: 3.5464 - acc: 0.1198\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 7s - loss: 3.5404 - acc: 0.1274\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 7s - loss: 3.5348 - acc: 0.1339\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 6s - loss: 3.5291 - acc: 0.1313\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 6s - loss: 3.5191 - acc: 0.1504\n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 5s - loss: 3.5109 - acc: 0.1489\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 5s - loss: 3.4994 - acc: 0.1510\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 4s - loss: 3.4871 - acc: 0.1513\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 4s - loss: 3.4700 - acc: 0.1531\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 3s - loss: 3.4560 - acc: 0.1518\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 3s - loss: 3.4366 - acc: 0.1491\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 2s - loss: 3.4102 - acc: 0.1508\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 2s - loss: 3.3848 - acc: 0.1497\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 2s - loss: 3.3554 - acc: 0.1525\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 1s - loss: 3.3216 - acc: 0.1502\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 3.2870 - acc: 0.1528\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 3.2581 - acc: 0.1518\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 3.2217 - acc: 0.1541\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 14s 14ms/step - loss: 3.1986 - acc: 0.1558 - val_loss: 2.0606 - val_acc: 0.2600\n\nEpoch 2/5\n\n 32/950 [\u003e.............................] - ETA: 11s - loss: 2.3107 - acc: 0.1562\n\n 64/950 [\u003d\u003e............................] - ETA: 11s - loss: 2.2550 - acc: 0.1562\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 10s - loss: 2.2856 - acc: 0.1458\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 10s - loss: 2.2343 - acc: 0.1719\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 10s - loss: 2.2227 - acc: 0.1625\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 9s - loss: 2.2139 - acc: 0.1615 \n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 9s - loss: 2.2049 - acc: 0.1518\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 8s - loss: 2.1700 - acc: 0.1680\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 8s - loss: 2.1539 - acc: 0.1875\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 8s - loss: 2.1428 - acc: 0.1938\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 7s - loss: 2.1369 - acc: 0.1875\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 7s - loss: 2.1182 - acc: 0.1953\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 6s - loss: 2.1193 - acc: 0.1947\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 6s - loss: 2.1117 - acc: 0.1942\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 6s - loss: 2.1025 - acc: 0.2000\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 5s - loss: 2.0949 - acc: 0.2031\n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 5s - loss: 2.0986 - acc: 0.1949\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 4s - loss: 2.0929 - acc: 0.1944\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 4s - loss: 2.0904 - acc: 0.1908\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 3s - loss: 2.0820 - acc: 0.1922\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 3s - loss: 2.0785 - acc: 0.1875\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 3s - loss: 2.0737 - acc: 0.1832\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 2s - loss: 2.0613 - acc: 0.1861\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 2s - loss: 2.0525 - acc: 0.1875\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 1s - loss: 2.0535 - acc: 0.1850\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 1s - loss: 2.0448 - acc: 0.1887\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 2.0423 - acc: 0.1852\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 2.0396 - acc: 0.1819\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 2.0427 - acc: 0.1789\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 13s 13ms/step - loss: 2.0443 - acc: 0.1779 - val_loss: 1.8980 - val_acc: 0.0600\n\nEpoch 3/5\n\n 32/950 [\u003e.............................] - ETA: 11s - loss: 1.9012 - acc: 0.1562\n\n 64/950 [\u003d\u003e............................] - ETA: 11s - loss: 1.8997 - acc: 0.2031\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 10s - loss: 1.9527 - acc: 0.1771\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 10s - loss: 1.9547 - acc: 0.1484\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 10s - loss: 1.9393 - acc: 0.1500\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 9s - loss: 1.9365 - acc: 0.1615 \n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 9s - loss: 1.9249 - acc: 0.1786\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 8s - loss: 1.9162 - acc: 0.1836\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 8s - loss: 1.9137 - acc: 0.1875\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 8s - loss: 1.9041 - acc: 0.1844\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 7s - loss: 1.9125 - acc: 0.1790\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 7s - loss: 1.9154 - acc: 0.1823\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 6s - loss: 1.9116 - acc: 0.1827\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 6s - loss: 1.9034 - acc: 0.1853\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 6s - loss: 1.8977 - acc: 0.1938\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 5s - loss: 1.9236 - acc: 0.1816\n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 5s - loss: 1.9231 - acc: 0.1820\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 4s - loss: 1.9347 - acc: 0.1788\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 4s - loss: 1.9352 - acc: 0.1809\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 3s - loss: 1.9350 - acc: 0.1828\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 3s - loss: 1.9388 - acc: 0.1845\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 3s - loss: 1.9396 - acc: 0.1847\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 2s - loss: 1.9409 - acc: 0.1848\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 2s - loss: 1.9372 - acc: 0.1823\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 1s - loss: 1.9326 - acc: 0.1837\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 1s - loss: 1.9313 - acc: 0.1839\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 1.9269 - acc: 0.1840\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 1.9298 - acc: 0.1864\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 1.9310 - acc: 0.1886\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 13s 13ms/step - loss: 1.9310 - acc: 0.1895 - val_loss: 1.8100 - val_acc: 0.3000\n\nEpoch 4/5\n\n 32/950 [\u003e.............................] - ETA: 11s - loss: 1.9696 - acc: 0.2188\n\n 64/950 [\u003d\u003e............................] - ETA: 11s - loss: 1.9190 - acc: 0.2031\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 10s - loss: 1.8979 - acc: 0.2083\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 10s - loss: 1.8847 - acc: 0.2266\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 10s - loss: 1.8950 - acc: 0.2188\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 9s - loss: 1.9067 - acc: 0.2135 \n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 9s - loss: 1.9112 - acc: 0.2054\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 8s - loss: 1.9116 - acc: 0.1992\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 8s - loss: 1.8964 - acc: 0.2118\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 8s - loss: 1.8989 - acc: 0.2156\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 7s - loss: 1.8989 - acc: 0.2159\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 7s - loss: 1.8994 - acc: 0.2109\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 6s - loss: 1.8951 - acc: 0.2163\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 6s - loss: 1.8921 - acc: 0.2165\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 6s - loss: 1.8901 - acc: 0.2229\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 5s - loss: 1.8822 - acc: 0.2246\n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 5s - loss: 1.8812 - acc: 0.2279\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 4s - loss: 1.8858 - acc: 0.2274\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 4s - loss: 1.8888 - acc: 0.2253\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 3s - loss: 1.8923 - acc: 0.2219\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 3s - loss: 1.8960 - acc: 0.2232\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 3s - loss: 1.8976 - acc: 0.2216\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 2s - loss: 1.8972 - acc: 0.2215\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 2s - loss: 1.8962 - acc: 0.2201\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 1s - loss: 1.8938 - acc: 0.2175\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 1s - loss: 1.8946 - acc: 0.2139\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 1.8979 - acc: 0.2118\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 1.8931 - acc: 0.2143\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 1.8860 - acc: 0.2188\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 13s 13ms/step - loss: 1.8864 - acc: 0.2179 - val_loss: 1.8257 - val_acc: 0.0600\n\nEpoch 5/5\n\n 32/950 [\u003e.............................] - ETA: 11s - loss: 1.8823 - acc: 0.0938\n\n 64/950 [\u003d\u003e............................] - ETA: 11s - loss: 1.9067 - acc: 0.1406\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 11s - loss: 1.8744 - acc: 0.1562\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 10s - loss: 1.8704 - acc: 0.1641\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 10s - loss: 1.8765 - acc: 0.1750\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 9s - loss: 1.8607 - acc: 0.1771 \n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 9s - loss: 1.8610 - acc: 0.1830\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 8s - loss: 1.8701 - acc: 0.1680\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 8s - loss: 1.8746 - acc: 0.1736\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 8s - loss: 1.8787 - acc: 0.1719\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 7s - loss: 1.8790 - acc: 0.1818\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 7s - loss: 1.8866 - acc: 0.1745\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 6s - loss: 1.8928 - acc: 0.1683\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 6s - loss: 1.8904 - acc: 0.1674\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 6s - loss: 1.8904 - acc: 0.1667\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 5s - loss: 1.8882 - acc: 0.1621\n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 5s - loss: 1.8886 - acc: 0.1599\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 4s - loss: 1.8883 - acc: 0.1632\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 4s - loss: 1.8895 - acc: 0.1694\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 4s - loss: 1.8889 - acc: 0.1734\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 3s - loss: 1.8937 - acc: 0.1771\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 3s - loss: 1.8933 - acc: 0.1747\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 2s - loss: 1.8939 - acc: 0.1726\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 2s - loss: 1.8913 - acc: 0.1732\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 1s - loss: 1.8935 - acc: 0.1713\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 1s - loss: 1.8881 - acc: 0.1743\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 1.8908 - acc: 0.1736\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 1.8896 - acc: 0.1763\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 1.8877 - acc: 0.1756\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 13s 13ms/step - loss: 1.8853 - acc: 0.1779 - val_loss: 1.8291 - val_acc: 0.0600\n\n\n  32/1000 [..............................] - ETA: 5s\n\n  64/1000 [\u003e.............................] - ETA: 5s\n\n  96/1000 [\u003d\u003e............................] - ETA: 5s\n\n 128/1000 [\u003d\u003d\u003e...........................] - ETA: 4s\n\n 160/1000 [\u003d\u003d\u003d\u003e..........................] - ETA: 4s\n\n 192/1000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 4s\n\n 224/1000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 4s\n\n 256/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 4s\n\n 288/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 4s\n\n 320/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 3s\n\n 352/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 3s\n\n 384/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 3s\n\n 416/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s\n\n 448/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 3s\n\n 480/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 2s\n\n 512/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 2s\n\n 544/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 2s\n\n 576/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 2s\n\n 608/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 2s\n\n 640/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 2s\n\n 672/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 1s\n\n 704/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 1s\n\n 736/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 1s\n\n 768/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 1s\n\n 800/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s\n\n 832/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s\n\n 864/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s\n\n 896/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s\n\n 928/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s\n\n 960/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s\n\n 992/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s\n\n1000/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 6s 6ms/step\n\nTest loss / test accuracy \u003d 1.8289 / 0.1870\n"
      },
      "dateCreated": "Jan 15, 2018 12:29:01 PM",
      "dateStarted": "Jan 24, 2018 10:28:25 AM",
      "dateFinished": "Jan 24, 2018 10:29:38 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Model :- RNN.\nInput :- Facebook bAbI dataset. Contains stories etc. Contains 10000 training stories.\nThe file format for each task is as follows:\nID text\nID text\nID text\nID question[tab]answer[tab]supporting fact IDS.\n...\n\nThe IDs for a given \"story\" start at 1 and increase.\nWhen the IDs in a file reset back to 1 you can consider the following sentences as a new \"story\".\n\nOutput :- Accuracy which is calculated as : questions are asked based on the stories and its accuracy is measured. Real number in the range 0-1.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 24, 2018 10:28:25 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516019440778_-1534706536",
      "id": "20180115-123040_1534675501_q_WS9XDM1E8C1516598377",
      "dateCreated": "Jan 15, 2018 12:30:40 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 24, 2018 10:28:25 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516361177606_-2028088073",
      "id": "20180119-112617_1011562802_q_WS9XDM1E8C1516598377",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 19, 2018 11:26:17 AM",
      "dateStarted": "Jan 24, 2018 10:28:26 AM",
      "dateFinished": "Jan 24, 2018 10:29:38 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "bAbI_RNN",
  "id": "WS9XDM1E8C1516598377",
  "angularObjects": {
    "2D6B43M8G932661515762929145:shared_process": [],
    "2D35KXZZK932661515762929137:shared_process": [],
    "2D6BD75VQ932661515762929141:shared_process": []
  },
  "config": {
    "isDashboard": false
  },
  "info": {},
  "source": "FCN"
}