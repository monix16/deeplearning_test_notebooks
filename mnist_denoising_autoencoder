{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027\nos.environ[\u0027MKL_THREADING_LAYER\u0027] \u003d \"GNU\"",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 7:13:15 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516358205773_-1425298381",
      "id": "20180119-103645_58012745_q_P4N59U4BZF1527181784",
      "dateCreated": "Jan 19, 2018 10:36:45 AM",
      "dateSubmitted": "May 24, 2018 5:10:20 PM",
      "dateStarted": "May 24, 2018 5:10:35 PM",
      "dateFinished": "May 24, 2018 5:10:56 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "dateUpdated": "Jan 22, 2018 1:19:58 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516358216047_494229205",
      "id": "20180119-103656_284441402_q_P4N59U4BZF1527181784",
      "dateCreated": "Jan 19, 2018 10:36:56 AM",
      "dateSubmitted": "May 24, 2018 5:10:35 PM",
      "dateStarted": "May 24, 2018 5:10:56 PM",
      "dateFinished": "May 24, 2018 5:10:57 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport keras\nfrom keras.layers import Activation, Dense, Input\nfrom keras.layers import Conv2D, Flatten\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nnp.random.seed(1337)\n\n# MNIST dataset\n(x_train, _), (x_test, _) \u003d mnist.load_data()\n\nimage_size \u003d x_train.shape[1]\nx_train \u003d np.reshape(x_train, [-1, image_size, image_size, 1])\nx_test \u003d np.reshape(x_test, [-1, image_size, image_size, 1])\nx_train \u003d x_train.astype(\u0027float32\u0027) / 255\nx_test \u003d x_test.astype(\u0027float32\u0027) / 255\n\n# Generate corrupted MNIST images by adding noise with normal dist\n# centered at 0.5 and std\u003d0.5\nnoise \u003d np.random.normal(loc\u003d0.5, scale\u003d0.5, size\u003dx_train.shape)\nx_train_noisy \u003d x_train + noise\nnoise \u003d np.random.normal(loc\u003d0.5, scale\u003d0.5, size\u003dx_test.shape)\nx_test_noisy \u003d x_test + noise\n\nx_train_noisy \u003d np.clip(x_train_noisy, 0., 1.)\nx_test_noisy \u003d np.clip(x_test_noisy, 0., 1.)\n\n# Network parameters\ninput_shape \u003d (image_size, image_size, 1)\nbatch_size \u003d 128\nkernel_size \u003d 3\nlatent_dim \u003d 16\n# Encoder/Decoder number of CNN layers and filters per layer\nlayer_filters \u003d [32, 64]\n\n# Build the Autoencoder Model\n# First build the Encoder Model\ninputs \u003d Input(shape\u003dinput_shape, name\u003d\u0027encoder_input\u0027)\nx \u003d inputs\n# Stack of Conv2D blocks\n# Notes:\n# 1) Use Batch Normalization before ReLU on deep networks\n# 2) Use MaxPooling2D as alternative to strides\u003e1\n# - faster but not as good as strides\u003e1\nfor filters in layer_filters:\n    x \u003d Conv2D(filters\u003dfilters,\n               kernel_size\u003dkernel_size,\n               strides\u003d2,\n               activation\u003d\u0027relu\u0027,\n               padding\u003d\u0027same\u0027)(x)\n\n# Shape info needed to build Decoder Model\nshape \u003d K.int_shape(x)\n\n# Generate the latent vector\nx \u003d Flatten()(x)\nlatent \u003d Dense(latent_dim, name\u003d\u0027latent_vector\u0027)(x)\n\n# Instantiate Encoder Model\nencoder \u003d Model(inputs, latent, name\u003d\u0027encoder\u0027)\nencoder.summary()\n\n# Build the Decoder Model\nlatent_inputs \u003d Input(shape\u003d(latent_dim,), name\u003d\u0027decoder_input\u0027)\nx \u003d Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\nx \u003d Reshape((shape[1], shape[2], shape[3]))(x)\n\n# Stack of Transposed Conv2D blocks\n# Notes:\n# 1) Use Batch Normalization before ReLU on deep networks\n# 2) Use UpSampling2D as alternative to strides\u003e1\n# - faster but not as good as strides\u003e1\nfor filters in layer_filters[::-1]:\n    x \u003d Conv2DTranspose(filters\u003dfilters,\n                        kernel_size\u003dkernel_size,\n                        strides\u003d2,\n                        activation\u003d\u0027relu\u0027,\n                        padding\u003d\u0027same\u0027)(x)\n\nx \u003d Conv2DTranspose(filters\u003d1,\n                    kernel_size\u003dkernel_size,\n                    padding\u003d\u0027same\u0027)(x)\n\noutputs \u003d Activation(\u0027sigmoid\u0027, name\u003d\u0027decoder_output\u0027)(x)\n\n# Instantiate Decoder Model\ndecoder \u003d Model(latent_inputs, outputs, name\u003d\u0027decoder\u0027)\ndecoder.summary()\n\n# Autoencoder \u003d Encoder + Decoder\n# Instantiate Autoencoder Model\nautoencoder \u003d Model(inputs, decoder(encoder(inputs)), name\u003d\u0027autoencoder\u0027)\nautoencoder.summary()\n\nautoencoder.compile(loss\u003d\u0027mse\u0027, optimizer\u003d\u0027adam\u0027)\n\n# Train the autoencoder\nautoencoder.fit(x_train_noisy,\n                x_train,\n                validation_data\u003d(x_test_noisy, x_test),\n                epochs\u003d1,\n                batch_size\u003dbatch_size)\n\n# Predict the Autoencoder output from corrupted test images\nx_decoded \u003d autoencoder.predict(x_test_noisy)\n\n# Display the 1st 8 corrupted and denoised images\nrows, cols \u003d 10, 30\nnum \u003d rows * cols\nimgs \u003d np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\nimgs \u003d imgs.reshape((rows * 3, cols, image_size, image_size))\nimgs \u003d np.vstack(np.split(imgs, rows, axis\u003d1))\nimgs \u003d imgs.reshape((rows * 3, -1, image_size, image_size))\nimgs \u003d np.vstack([np.hstack(i) for i in imgs])\nimgs \u003d (imgs * 255).astype(np.uint8)\nplt.figure()\nplt.axis(\u0027off\u0027)\nplt.title(\u0027Original images: top rows, \u0027\n          \u0027Corrupted Input: middle rows, \u0027\n          \u0027Denoised Input:  third rows\u0027)\nplt.imshow(imgs, interpolation\u003d\u0027none\u0027, cmap\u003d\u0027gray\u0027)\nImage.fromarray(imgs).save(\u0027corrupted_and_denoised.png\u0027)\nplt.show()",
      "dateUpdated": "Jan 19, 2018 5:39:55 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516097040408_-317123438",
      "id": "20180116-100400_1512843571_q_P4N59U4BZF1527181784",
      "dateCreated": "Jan 16, 2018 10:04:00 AM",
      "dateSubmitted": "May 24, 2018 5:10:56 PM",
      "dateStarted": "May 24, 2018 5:10:57 PM",
      "dateFinished": "May 24, 2018 5:10:57 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Train the autoencoder to reconstruct the input from a corrupted version of it.\n\nInput : The MNIST dataset contains 60000 training images of 28x28 size and 10000 testing greyscale images of 28x28 size.\n    \n    The dataset is divided into one training batch with 60000 images and one test batch with 10000 images.\n    \n    Each batch contains a dictionary with the following elements:-\n    \n    data -- a 60000x28x28 numpy array of uint8s in case of training sample and 10000x28x28 numpy array of uint8s in case of testing sample. The first dimension of the array \n    marks the image number and the other dimensions is for the image matrix.\n    labels -- a list of 60000 numbers which are either 0 or 1 for training sample and 10000 numbers  for testing sample. The number at index i indicates the label of the ith            image in the array data.\nOutput : Corrupted and denoised images stacked to each other in .png format.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 19, 2018 5:39:36 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516107402228_2052884035",
      "id": "20180116-125642_493641898_q_P4N59U4BZF1527181784",
      "dateCreated": "Jan 16, 2018 12:56:42 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "mnist_denoising_autoencoder",
  "id": "P4N59U4BZF1527181784",
  "angularObjects": {
    "2DDTZVJUE1090031527181799774:shared_process": [],
    "2DEK3QV851090031527168688484:shared_process": [],
    "2DENTX6JV1090031527168688466:shared_process": [],
    "2DDED8P751090031527168688477:shared_process": [],
    "2DDBWFX441090031527168688480:shared_process": []
  },
  "config": {
    "isDashboard": false,
    "defaultLang": "pyspark"
  },
  "info": {},
  "source": "FCN"
}