{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027\nos.environ[\u0027MKL_THREADING_LAYER\u0027] \u003d \"GNU\"",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:36:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357998762_1248415315",
      "id": "20180119-103318_1133883740_q_P9Y9SXNEDD1527180884",
      "dateCreated": "Jan 19, 2018 10:33:18 AM",
      "dateSubmitted": "May 25, 2018 6:36:59 AM",
      "dateStarted": "May 25, 2018 6:36:59 AM",
      "dateFinished": "May 25, 2018 6:36:59 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:36:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516358004719_296561860",
      "id": "20180119-103324_603169642_q_P9Y9SXNEDD1527180884",
      "dateCreated": "Jan 19, 2018 10:33:24 AM",
      "dateSubmitted": "May 25, 2018 6:36:59 AM",
      "dateStarted": "May 25, 2018 6:36:59 AM",
      "dateFinished": "May 25, 2018 6:36:59 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from __future__ import print_function\nfrom keras.callbacks import LambdaCallback\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop\nfrom keras.utils.data_utils import get_file\nimport numpy as np\nfrom numpy import array\nimport random\nimport sys\nimport io\n\npath \u003d get_file(\u0027nietzsche.txt\u0027, origin\u003d\u0027https://s3.amazonaws.com/text-datasets/nietzsche.txt\u0027)\ntext \u003d io.open(path, encoding\u003d\u0027utf-8\u0027).read().lower()\nprint(\u0027corpus length:\u0027, len(text))\n\nchars \u003d sorted(list(set(text)))\nprint(\u0027total chars:\u0027, len(chars))\nchar_indices \u003d dict((c, i) for i, c in enumerate(chars))\nindices_char \u003d dict((i, c) for i, c in enumerate(chars))\n\n# cut the text in semi-redundant sequences of maxlen characters\nmaxlen \u003d 40\nstep \u003d 3\nsentences \u003d []\nnext_chars \u003d []\nfor i in range(0, len(text) - maxlen, step):\n    sentences.append(text[i: i + maxlen])\n    next_chars.append(text[i + maxlen])\nprint(\u0027nb sequences:\u0027, len(sentences))\nprint(array(array(sentences)[0]).shape)\nprint(\u0027Vectorization...\u0027)\nx \u003d np.zeros((len(sentences), maxlen, len(chars)), dtype\u003dnp.bool)\ny \u003d np.zeros((len(sentences), len(chars)), dtype\u003dnp.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        x[i, t, char_indices[char]] \u003d 1\n    y[i, char_indices[next_chars[i]]] \u003d 1\n\n\n# build the model: a single LSTM\nprint(\u0027Build model...\u0027)\nmodel \u003d Sequential()\nmodel.add(LSTM(128, input_shape\u003d(maxlen, len(chars))))\nmodel.add(Dense(len(chars)))\nmodel.add(Activation(\u0027softmax\u0027))\n\noptimizer \u003d RMSprop(lr\u003d0.01)\nmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027, optimizer\u003doptimizer)\n\n\ndef sample(preds, temperature\u003d1.0):\n    # helper function to sample an index from a probability array\n    preds \u003d np.asarray(preds).astype(\u0027float64\u0027)\n    preds \u003d np.log(preds) / temperature\n    exp_preds \u003d np.exp(preds)\n    preds \u003d exp_preds / np.sum(exp_preds)\n    probas \u003d np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\n\ndef on_epoch_end(epoch, logs):\n    # Function invoked at end of each epoch. Prints generated text.\n    print()\n    print(\u0027----- Generating text after Epoch: %d\u0027 % epoch)\n\n    start_index \u003d random.randint(0, len(text) - maxlen - 1)\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\n        print(\u0027----- diversity:\u0027, diversity)\n\n        generated \u003d \u0027\u0027\n        sentence \u003d text[start_index: start_index + maxlen]\n        generated +\u003d sentence\n        print(\u0027----- Generating with seed: \"\u0027 + sentence + \u0027\"\u0027)\n        sys.stdout.write(generated)\n\n        for i in range(400):\n            x_pred \u003d np.zeros((1, maxlen, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] \u003d 1.\n\n            preds \u003d model.predict(x_pred, verbose\u003d0)[0]\n            next_index \u003d sample(preds, diversity)\n            next_char \u003d indices_char[next_index]\n\n            generated +\u003d next_char\n            sentence \u003d sentence[1:] + next_char\n\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()\n\nprint_callback \u003d LambdaCallback(on_epoch_end\u003don_epoch_end)\n\nmodel.fit(x, y,\n          batch_size\u003d128,\n          epochs\u003d2,\n          callbacks\u003d[print_callback])",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:36:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516096681246_1595206123",
      "id": "20180116-095801_415750060_q_P9Y9SXNEDD1527180884",
      "dateCreated": "Jan 16, 2018 9:58:01 AM",
      "dateSubmitted": "May 25, 2018 6:36:59 AM",
      "dateStarted": "May 25, 2018 6:36:59 AM",
      "dateFinished": "May 25, 2018 6:41:23 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Example script to generate text from Nietzsche\u0027s writings.\nInput : Total 200285 words or rows of different length.\nOutput : Sample Texts generated by the model.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:36:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516100268155_556297604",
      "id": "20180116-105748_773953902_q_P9Y9SXNEDD1527180884",
      "dateCreated": "Jan 16, 2018 10:57:48 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:36:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516606589120_1292323825",
      "id": "20180122-073629_1819414481_q_P9Y9SXNEDD1527180884",
      "dateCreated": "Jan 22, 2018 7:36:29 AM",
      "dateSubmitted": "May 25, 2018 6:36:59 AM",
      "dateStarted": "May 25, 2018 6:41:23 AM",
      "dateFinished": "May 25, 2018 6:41:23 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "lstm_text_generation",
  "id": "P9Y9SXNEDD1527180884",
  "angularObjects": {
    "2DEK3QV851090031527168688484:shared_process": [],
    "2DENTX6JV1090031527168688466:shared_process": [],
    "2DG7U3DAR1090031527180899689:shared_process": [],
    "2DDED8P751090031527168688477:shared_process": [],
    "2DE8JRQYX1090031527228139990:shared_process": [],
    "2DDBWFX441090031527168688480:shared_process": []
  },
  "config": {
    "isDashboard": false,
    "defaultLang": "pyspark"
  },
  "info": {},
  "source": "FCN"
}