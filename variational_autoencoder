{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 23, 2018 5:03:16 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516604156065_-1114911005",
      "id": "20180122-065556_1190969499_q_FAYQQJXCSD1516359719",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 22, 2018 6:55:56 AM",
      "dateStarted": "Jan 23, 2018 5:03:16 AM",
      "dateFinished": "Jan 23, 2018 5:05:42 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 23, 2018 5:03:16 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516604162386_-1825326040",
      "id": "20180122-065602_282889477_q_FAYQQJXCSD1516359719",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "Using Theano backend.\nUsing cuDNN version 6021 on context None\nMapped name None to device cuda: GRID K520 (0000:00:03.0)\ntheano\n"
      },
      "dateCreated": "Jan 22, 2018 6:56:02 AM",
      "dateStarted": "Jan 23, 2018 5:04:55 AM",
      "dateFinished": "Jan 23, 2018 5:06:47 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nfrom keras.layers import Input, Dense, Lambda, Layer\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras.datasets import mnist\n\nbatch_size \u003d 100\noriginal_dim \u003d 784\nlatent_dim \u003d 2\nintermediate_dim \u003d 256\nepochs \u003d 5\nepsilon_std \u003d 1.0\n\n\nx \u003d Input(shape\u003d(original_dim,))\nh \u003d Dense(intermediate_dim, activation\u003d\u0027relu\u0027)(x)\nz_mean \u003d Dense(latent_dim)(h)\nz_log_var \u003d Dense(latent_dim)(h)\n\n\ndef sampling(args):\n    z_mean, z_log_var \u003d args\n    epsilon \u003d K.random_normal(shape\u003d(K.shape(z_mean)[0], latent_dim), mean\u003d0.,\n                              stddev\u003depsilon_std)\n    return z_mean + K.exp(z_log_var / 2) * epsilon\n\n# note that \"output_shape\" isn\u0027t necessary with the TensorFlow backend\nz \u003d Lambda(sampling, output_shape\u003d(latent_dim,))([z_mean, z_log_var])\n\n# we instantiate these layers separately so as to reuse them later\ndecoder_h \u003d Dense(intermediate_dim, activation\u003d\u0027relu\u0027)\ndecoder_mean \u003d Dense(original_dim, activation\u003d\u0027sigmoid\u0027)\nh_decoded \u003d decoder_h(z)\nx_decoded_mean \u003d decoder_mean(h_decoded)\n\n\n# Custom loss layer\nclass CustomVariationalLayer(Layer):\n    def __init__(self, **kwargs):\n        self.is_placeholder \u003d True\n        super(CustomVariationalLayer, self).__init__(**kwargs)\n\n    def vae_loss(self, x, x_decoded_mean):\n        xent_loss \u003d original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n        kl_loss \u003d - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis\u003d-1)\n        return K.mean(xent_loss + kl_loss)\n\n    def call(self, inputs):\n        x \u003d inputs[0]\n        x_decoded_mean \u003d inputs[1]\n        loss \u003d self.vae_loss(x, x_decoded_mean)\n        self.add_loss(loss, inputs\u003dinputs)\n        # We won\u0027t actually use the output.\n        return x\n\ny \u003d CustomVariationalLayer()([x, x_decoded_mean])\nvae \u003d Model(x, y)\nvae.compile(optimizer\u003d\u0027rmsprop\u0027, loss\u003dNone)\n\n\n# train the VAE on MNIST digits\n(x_train, y_train), (x_test, y_test) \u003d mnist.load_data()\n\nx_train \u003d x_train.astype(\u0027float32\u0027) / 255.\nx_test \u003d x_test.astype(\u0027float32\u0027) / 255.\nx_train \u003d x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test \u003d x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\nvae.fit(x_train,\n        shuffle\u003dTrue,\n        epochs\u003depochs,\n        batch_size\u003dbatch_size,\n        validation_data\u003d(x_test, None))\n\n# build a model to project inputs on the latent space\nencoder \u003d Model(x, z_mean)\n\n# display a 2D plot of the digit classes in the latent space\nx_test_encoded \u003d encoder.predict(x_test, batch_size\u003dbatch_size)\nplt.figure(figsize\u003d(6, 6))\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c\u003dy_test)\nplt.colorbar()\nplt.show()\n\n# build a digit generator that can sample from the learned distribution\ndecoder_input \u003d Input(shape\u003d(latent_dim,))\n_h_decoded \u003d decoder_h(decoder_input)\n_x_decoded_mean \u003d decoder_mean(_h_decoded)\ngenerator \u003d Model(decoder_input, _x_decoded_mean)\n\n# display a 2D manifold of the digits\nn \u003d 15  # figure with 15x15 digits\ndigit_size \u003d 28\nfigure \u003d np.zeros((digit_size * n, digit_size * n))\n# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n# to produce values of the latent variables z, since the prior of the latent space is Gaussian\ngrid_x \u003d norm.ppf(np.linspace(0.05, 0.95, n))\ngrid_y \u003d norm.ppf(np.linspace(0.05, 0.95, n))\n\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample \u003d np.array([[xi, yi]])\n        x_decoded \u003d generator.predict(z_sample)\n        digit \u003d x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] \u003d digit\n\nplt.figure(figsize\u003d(10, 10))\nplt.imshow(figure, cmap\u003d\u0027Greys_r\u0027)\nplt.show()",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 23, 2018 5:04:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516098552475_-1019514586",
      "id": "20180116-102912_16248349_q_FAYQQJXCSD1516359719",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "/tmp/zeppelin_pyspark-8372218982897563.py:45: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n  \nDownloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n\n    8192/11490434 [..............................] - ETA: 1s\n\n 3260416/11490434 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 0s\n\n 8421376/11490434 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s\n\n11493376/11490434 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s 0us/step\n\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/5\n\n  100/60000 [..............................] - ETA: 3:53 - loss: 543.9929\n\n 2000/60000 [\u003e.............................] - ETA: 12s - loss: 344.5557 \n\n 3500/60000 [\u003e.............................] - ETA: 7s - loss: 302.1604 \n\n 5400/60000 [\u003d\u003e............................] - ETA: 5s - loss: 274.3590\n\n 7300/60000 [\u003d\u003d\u003e...........................] - ETA: 4s - loss: 257.6947\n\n 9300/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 3s - loss: 245.1298\n\n11300/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 3s - loss: 236.7020\n\n13200/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 2s - loss: 230.2292\n\n15200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 2s - loss: 224.9883\n\n17200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 2s - loss: 220.6172\n\n19200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 217.0942\n\n21200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s - loss: 214.2647\n\n23200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 1s - loss: 211.8038\n\n25100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 1s - loss: 209.6505\n\n27100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 1s - loss: 207.6054\n\n28600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 1s - loss: 206.1411\n\n30500/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 1s - loss: 204.5240\n\n32500/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 1s - loss: 203.0102\n\n34500/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 201.5225\n\n36400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 200.2521\n\n38400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 199.0166\n\n40300/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 198.0368\n\n42200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 197.0184\n\n44100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 196.0601\n\n46000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 195.2855\n\n47900/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 194.4336\n\n49800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 193.5964\n\n51300/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 193.0327\n\n53000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 192.4236\n\n54800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 191.7991\n\n56600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 191.2202\n\n58600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 190.4896\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 35us/step - loss: 190.1021 - val_loss: 171.5007\n\nEpoch 2/5\n\n  100/60000 [..............................] - ETA: 2s - loss: 181.3705\n\n 2100/60000 [\u003e.............................] - ETA: 1s - loss: 172.9541\n\n 4000/60000 [\u003d\u003e............................] - ETA: 1s - loss: 173.6400\n\n 5600/60000 [\u003d\u003e............................] - ETA: 1s - loss: 173.0795\n\n 7500/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 172.5515\n\n 9500/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 171.5981\n\n11500/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 171.9006\n\n13500/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 171.8284\n\n15500/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 171.6202\n\n17400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 171.5964\n\n19400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 171.4253\n\n21300/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s - loss: 171.3255\n\n23100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 171.3715\n\n25000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 171.1878\n\n26800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 171.1095\n\n28800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 171.0042\n\n30800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 170.9589\n\n32800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 170.8178\n\n34800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 170.6918\n\n36800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 170.6081\n\n38800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 170.4874\n\n40800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 170.3178\n\n42800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 170.2072\n\n44800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 170.1978\n\n46800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 170.1467\n\n48500/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 170.1391\n\n50300/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 170.0631\n\n52100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 169.9355\n\n53800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 169.8386\n\n55800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 169.7673\n\n57700/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 169.6731\n\n59700/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 169.5762\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 28us/step - loss: 169.5671 - val_loss: 167.5964\n\nEpoch 3/5\n\n  100/60000 [..............................] - ETA: 2s - loss: 164.3388\n\n 2100/60000 [\u003e.............................] - ETA: 1s - loss: 166.9116\n\n 4100/60000 [\u003d\u003e............................] - ETA: 1s - loss: 165.7449\n\n 6100/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 165.9767\n\n 8100/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 166.3401\n\n10100/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 166.8102\n\n11800/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 167.0695\n\n13500/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 166.8247\n\n15400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 166.8718\n\n17200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 166.9331\n\n19200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 166.6994\n\n21100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s - loss: 166.6898\n\n23000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 1s - loss: 166.6663\n\n24700/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 166.6455\n\n26400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 166.5412\n\n28100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 166.5790\n\n30100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 166.6166\n\n31900/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 166.6808\n\n33800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 166.5842\n\n35800/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 166.6048\n\n37700/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 166.5943\n\n39600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 166.6269\n\n41500/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 166.6766\n\n43400/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 166.6361\n\n45300/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 166.6512\n\n47200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 166.6686\n\n49200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 166.7086\n\n51200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 166.6633\n\n53200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 166.5824\n\n55200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 166.5125\n\n57200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 166.5091\n\n59200/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 166.4452\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 28us/step - loss: 166.4026 - val_loss: 165.4401\n\nEpoch 4/5\n\n  100/60000 [..............................] - ETA: 2s - loss: 168.0005\n\n 2100/60000 [\u003e.............................] - ETA: 1s - loss: 167.0402\n\n 4100/60000 [\u003d\u003e............................] - ETA: 1s - loss: 165.6234\n\n 6100/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 165.3075\n\n 8100/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 165.1593\n\n10100/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 165.1859\n\n12100/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 165.2311\n\n14100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 165.0707\n\n16100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 164.9913\n\n18100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 165.1715\n\n20100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s - loss: 165.2224\n\n22100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 165.2975\n\n24100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 165.0984\n\n26100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 164.8836\n\n28100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 164.8691\n\n30100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 164.8161\n\n32100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 164.8038\n\n34100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 164.7693\n\n36100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 164.6919\n\n38100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 164.6502\n\n40100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 164.6875\n\n42100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 164.6852\n\n44100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 164.6042\n\n46100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 164.6155\n\n48100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 164.5860\n\n50100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 164.4897\n\n52100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 164.4705\n\n54100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 164.4275\n\n56100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 164.4147\n\n58100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 164.3389\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 27us/step - loss: 164.3097 - val_loss: 163.7020\n\nEpoch 5/5\n\n  100/60000 [..............................] - ETA: 2s - loss: 159.4454\n\n 2100/60000 [\u003e.............................] - ETA: 1s - loss: 162.1939\n\n 4100/60000 [\u003d\u003e............................] - ETA: 1s - loss: 162.6736\n\n 6100/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 162.8053\n\n 8100/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 162.9544\n\n10100/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 162.9726\n\n12100/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 163.1204\n\n14100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 163.3752\n\n16100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 1s - loss: 163.0741\n\n18100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 1s - loss: 162.8892\n\n20100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 1s - loss: 162.8534\n\n22100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 162.9819\n\n24100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 162.9451\n\n26100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 162.9575\n\n28100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 162.8736\n\n30100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 162.9231\n\n32100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 163.0090\n\n34100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 163.0287\n\n36100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 163.0054\n\n38100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 162.9569\n\n40100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 162.9891\n\n42100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 163.0612\n\n44100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 163.0573\n\n46100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 163.0450\n\n48100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 163.0134\n\n50100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 163.0237\n\n52100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 162.9152\n\n54100/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 162.8832\n\n56000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 162.8887\n\n57900/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 162.9353\n\n59600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 162.9210\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 27us/step - loss: 162.8896 - val_loss: 162.5270\n\n"
      },
      "dateCreated": "Jan 16, 2018 10:29:12 AM",
      "dateStarted": "Jan 23, 2018 5:05:50 AM",
      "dateFinished": "Jan 23, 2018 5:08:28 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\nVariational autoencoders\n are generative algorithm that add an additional constraint to encoding the input data, namely that the hidden representations are normalized. Variational autoencoders are capable of both compressing data like an autoencoder and synthesizing data like a GAN.\n\nInput : The MNIST dataset contains 60000 training images of 28x28 size and 10000 testing greyscale images of 28x28 size.\n    \n    The dataset is divided into one training batch with 60000 images and one test batch with 10000 images.\n    \n    Each batch contains a dictionary with the following elements:-\n    \n    data -- a 60000x28x28 numpy array of uint8s in case of training sample and 10000x28x28 numpy array of uint8s in case of testing sample. The first dimension of the array \n    marks the image number and the other dimensions is for the image matrix.\n    labels -- a list of 60000 numbers which are either 0 or 1 for training sample and 10000 numbers  for testing sample. The number at index i indicates the label of the ith            image in the array data.\n\nOutput : Accuracy of the classification done by the trained model. Real No. Between 0-1.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 23, 2018 5:04:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516170615175_1861384129",
      "id": "20180117-063015_1739683036_q_FAYQQJXCSD1516359719",
      "dateCreated": "Jan 17, 2018 6:30:15 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516683894812_289922498",
      "id": "20180123-050454_551087657_q_FAYQQJXCSD1516359719",
      "dateCreated": "Jan 23, 2018 5:04:54 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "variational_autoencoder",
  "id": "FAYQQJXCSD1516359719",
  "angularObjects": {
    "2D7M1HZP5932661518613479637:shared_process": [],
    "2D6B43M8G932661515762929145:shared_process": [],
    "2D35KXZZK932661515762929137:shared_process": []
  },
  "config": {
    "isDashboard": false
  },
  "info": {},
  "source": "FCN"
}