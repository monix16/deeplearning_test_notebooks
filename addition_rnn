{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027\nos.environ[\u0027MKL_THREADING_LAYER\u0027] \u003d \"GNU\"",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:42:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357178505_-1986730225",
      "id": "20180119-101938_313212079_q_M7F9CT33DN1527180888",
      "dateCreated": "Jan 19, 2018 10:19:38 AM",
      "dateSubmitted": "May 25, 2018 6:42:05 AM",
      "dateStarted": "May 25, 2018 6:42:05 AM",
      "dateFinished": "May 25, 2018 6:42:05 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:42:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357188663_-108755520",
      "id": "20180119-101948_1949319483_q_M7F9CT33DN1527180888",
      "dateCreated": "Jan 19, 2018 10:19:48 AM",
      "dateSubmitted": "May 25, 2018 6:42:05 AM",
      "dateStarted": "May 25, 2018 6:42:05 AM",
      "dateFinished": "May 25, 2018 6:42:05 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from __future__ import print_function\nfrom keras.models import Sequential\nfrom keras import layers\nimport numpy as np\nfrom six.moves import range\n\n\nclass CharacterTable(object):\n    \"\"\"Given a set of characters:\n    + Encode them to a one hot integer representation\n    + Decode the one hot integer representation to their character output\n    + Decode a vector of probabilities to their character output\n    \"\"\"\n    def __init__(self, chars):\n        \"\"\"Initialize character table.\n        # Arguments\n            chars: Characters that can appear in the input.\n        \"\"\"\n        self.chars \u003d sorted(set(chars))\n        self.char_indices \u003d dict((c, i) for i, c in enumerate(self.chars))\n        self.indices_char \u003d dict((i, c) for i, c in enumerate(self.chars))\n\n    def encode(self, C, num_rows):\n        \"\"\"One hot encode given string C.\n        # Arguments\n            num_rows: Number of rows in the returned one hot encoding. This is\n                used to keep the # of rows for each data the same.\n        \"\"\"\n        x \u003d np.zeros((num_rows, len(self.chars)))\n        for i, c in enumerate(C):\n            x[i, self.char_indices[c]] \u003d 1\n        return x\n\n    def decode(self, x, calc_argmax\u003dTrue):\n        if calc_argmax:\n            x \u003d x.argmax(axis\u003d-1)\n        return \u0027\u0027.join(self.indices_char[x] for x in x)\n\n\nclass colors:\n    ok \u003d \u0027\\033[92m\u0027\n    fail \u003d \u0027\\033[91m\u0027\n    close \u003d \u0027\\033[0m\u0027\n\n# Parameters for the model and dataset.\nTRAINING_SIZE \u003d 50000\nDIGITS \u003d 3\nINVERT \u003d True\n\n# Maximum length of input is \u0027int + int\u0027 (e.g., \u0027345+678\u0027). Maximum length of\n# int is DIGITS.\nMAXLEN \u003d DIGITS + 1 + DIGITS\n\n# All the numbers, plus sign and space for padding.\nchars \u003d \u00270123456789+ \u0027\nctable \u003d CharacterTable(chars)\n\nquestions \u003d []\nexpected \u003d []\nseen \u003d set()\nprint(\u0027Generating data...\u0027)\nwhile len(questions) \u003c TRAINING_SIZE:\n    f \u003d lambda: int(\u0027\u0027.join(np.random.choice(list(\u00270123456789\u0027))\n                    for i in range(np.random.randint(1, DIGITS + 1))))\n    a, b \u003d f(), f()\n    # Skip any addition questions we\u0027ve already seen\n    # Also skip any such that x+Y \u003d\u003d Y+x (hence the sorting).\n    key \u003d tuple(sorted((a, b)))\n    if key in seen:\n        continue\n    seen.add(key)\n    # Pad the data with spaces such that it is always MAXLEN.\n    q \u003d \u0027{}+{}\u0027.format(a, b)\n    query \u003d q + \u0027 \u0027 * (MAXLEN - len(q))\n    ans \u003d str(a + b)\n    # Answers can be of maximum size DIGITS + 1.\n    ans +\u003d \u0027 \u0027 * (DIGITS + 1 - len(ans))\n    if INVERT:\n        # Reverse the query, e.g., \u002712+345  \u0027 becomes \u0027  543+21\u0027. (Note the\n        # space used for padding.)\n        query \u003d query[::-1]\n    questions.append(query)\n    expected.append(ans)\nprint(\u0027Total addition questions:\u0027, len(questions))\n\nprint(\u0027Vectorization...\u0027)\nx \u003d np.zeros((len(questions), MAXLEN, len(chars)), dtype\u003dnp.bool)\ny \u003d np.zeros((len(questions), DIGITS + 1, len(chars)), dtype\u003dnp.bool)\nfor i, sentence in enumerate(questions):\n    x[i] \u003d ctable.encode(sentence, MAXLEN)\nfor i, sentence in enumerate(expected):\n    y[i] \u003d ctable.encode(sentence, DIGITS + 1)\n\n# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n# digits.\nindices \u003d np.arange(len(y))\nnp.random.shuffle(indices)\nx \u003d x[indices]\ny \u003d y[indices]\n\n# Explicitly set apart 10% for validation data that we never train over.\nsplit_at \u003d len(x) - len(x) // 10\n(x_train, x_val) \u003d x[:split_at], x[split_at:]\n(y_train, y_val) \u003d y[:split_at], y[split_at:]\n\nprint(\u0027Training Data:\u0027)\nprint(x_train.shape)\nprint(y_train.shape)\n\nprint(\u0027Validation Data:\u0027)\nprint(x_val.shape)\nprint(y_val.shape)\n\n# Try replacing GRU, or SimpleRNN.\nRNN \u003d layers.LSTM\nHIDDEN_SIZE \u003d 128\nBATCH_SIZE \u003d 128\nLAYERS \u003d 1\n\nprint(\u0027Build model...\u0027)\nmodel \u003d Sequential()\n# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n# Note: In a situation where your input sequences have a variable length,\n# use input_shape\u003d(None, num_feature).\nmodel.add(RNN(HIDDEN_SIZE, input_shape\u003d(MAXLEN, len(chars))))\n# As the decoder RNN\u0027s input, repeatedly provide with the last hidden state of\n# RNN for each time step. Repeat \u0027DIGITS + 1\u0027 times as that\u0027s the maximum\n# length of output, e.g., when DIGITS\u003d3, max output is 999+999\u003d1998.\nmodel.add(layers.RepeatVector(DIGITS + 1))\n# The decoder RNN could be multiple layers stacked or a single layer.\nfor _ in range(LAYERS):\n    # By setting return_sequences to True, return not only the last output but\n    # all the outputs so far in the form of (num_samples, timesteps,\n    # output_dim). This is necessary as TimeDistributed in the below expects\n    # the first dimension to be the timesteps.\n    model.add(RNN(HIDDEN_SIZE, return_sequences\u003dTrue))\n\n# Apply a dense layer to the every temporal slice of an input. For each of step\n# of the output sequence, decide which character should be chosen.\nmodel.add(layers.TimeDistributed(layers.Dense(len(chars))))\nmodel.add(layers.Activation(\u0027softmax\u0027))\nmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n              optimizer\u003d\u0027adam\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\nmodel.summary()\n\n# Train the model each generation and show predictions against the validation\n# dataset.\nfor iteration in range(1, 10):\n    print()\n    print(\u0027-\u0027 * 50)\n    print(\u0027Iteration\u0027, iteration)\n    model.fit(x_train, y_train,\n              batch_size\u003dBATCH_SIZE,\n              epochs\u003d1,\n              validation_data\u003d(x_val, y_val))\n    # Select 10 samples from the validation set at random so we can visualize\n    # errors.\n    for i in range(10):\n        ind \u003d np.random.randint(0, len(x_val))\n        rowx, rowy \u003d x_val[np.array([ind])], y_val[np.array([ind])]\n        preds \u003d model.predict_classes(rowx, verbose\u003d0)\n        q \u003d ctable.decode(rowx[0])\n        correct \u003d ctable.decode(rowy[0])\n        guess \u003d ctable.decode(preds[0], calc_argmax\u003dFalse)\n        print(\u0027Q\u0027, q[::-1] if INVERT else q, end\u003d\u0027 \u0027)\n        print(\u0027T\u0027, correct, end\u003d\u0027 \u0027)\n        if correct \u003d\u003d guess:\n            print(colors.ok + \u0027���\u0027 + colors.close, end\u003d\u0027 \u0027)\n        else:\n            print(colors.fail + \u0027���\u0027 + colors.close, end\u003d\u0027 \u0027)\n        print(guess)",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:42:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516015468935_1101366951",
      "id": "20180115-112428_347069860_q_M7F9CT33DN1527180888",
      "dateCreated": "Jan 15, 2018 11:24:28 AM",
      "dateSubmitted": "May 25, 2018 6:42:05 AM",
      "dateStarted": "May 25, 2018 6:42:05 AM",
      "dateFinished": "May 25, 2018 6:43:55 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Implementation of sequence to sequence learning to perform addition.\n\nInput :- Random questions are being created by the data generator. Input is string in one hot representation which is of the form \"a+b\" where \u0027a\u0027 and \u0027b\u0027 are numbers.\nOutput :- accuracy of addition which is done without converting the strings to numbers. Real Number between 0-1.\n",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:42:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516015477616_1968606296",
      "id": "20180115-112437_2090633851_q_M7F9CT33DN1527180888",
      "dateCreated": "Jan 15, 2018 11:24:37 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 6:42:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516360465292_779380323",
      "id": "20180119-111425_142290067_q_M7F9CT33DN1527180888",
      "dateCreated": "Jan 19, 2018 11:14:25 AM",
      "dateSubmitted": "May 25, 2018 6:42:06 AM",
      "dateStarted": "May 25, 2018 6:43:55 AM",
      "dateFinished": "May 25, 2018 6:43:55 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "addition_rnn",
  "id": "M7F9CT33DN1527180888",
  "angularObjects": {
    "2DEK3QV851090031527168688484:shared_process": [],
    "2DENTX6JV1090031527168688466:shared_process": [],
    "2DGDXDZTE1090031527180908412:shared_process": [],
    "2DDED8P751090031527168688477:shared_process": [],
    "2DE8JRQYX1090031527228139990:shared_process": [],
    "2DDBWFX441090031527168688480:shared_process": []
  },
  "config": {
    "isDashboard": false,
    "defaultLang": "pyspark"
  },
  "info": {},
  "source": "FCN"
}