{
  "paragraphs": [
    {
      "text": "from __future__ import print_function\n\nfrom scipy.misc import imsave\nimport numpy as np\nimport time\nfrom keras.applications import vgg16\nfrom keras import backend as K\n\n# dimensions of the generated pictures for each filter.\nimg_width \u003d 128\nimg_height \u003d 128\n\n# the name of the layer we want to visualize\n# (see model definition at keras/applications/vgg16.py)\nlayer_name \u003d \u0027block5_conv1\u0027\n\n# util function to convert a tensor into a valid image\n\n\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -\u003d x.mean()\n    x /\u003d (x.std() + K.epsilon())\n    x *\u003d 0.1\n\n    # clip to [0, 1]\n    x +\u003d 0.5\n    x \u003d np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *\u003d 255\n    if K.image_data_format() \u003d\u003d \u0027channels_first\u0027:\n        x \u003d x.transpose((1, 2, 0))\n    x \u003d np.clip(x, 0, 255).astype(\u0027uint8\u0027)\n    return x\n\n# build the VGG16 network with ImageNet weights\nmodel \u003d vgg16.VGG16(weights\u003d\u0027imagenet\u0027, include_top\u003dFalse)\nprint(\u0027Model loaded.\u0027)\n\nmodel.summary()\n\n# this is the placeholder for the input images\ninput_img \u003d model.input\n\n# get the symbolic outputs of each \"key\" layer (we gave them unique names).\nlayer_dict \u003d dict([(layer.name, layer) for layer in model.layers[1:]])\n\n\ndef normalize(x):\n    # utility function to normalize a tensor by its L2 norm\n    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n\n\nkept_filters \u003d []\nfor filter_index in range(20):\n    # we only scan through the first 200 filters,\n    # but there are actually 512 of them\n    print(\u0027Processing filter %d\u0027 % filter_index)\n    start_time \u003d time.time()\n\n    # we build a loss function that maximizes the activation\n    # of the nth filter of the layer considered\n    layer_output \u003d layer_dict[layer_name].output\n    if K.image_data_format() \u003d\u003d \u0027channels_first\u0027:\n        loss \u003d K.mean(layer_output[:, filter_index, :, :])\n    else:\n        loss \u003d K.mean(layer_output[:, :, :, filter_index])\n\n    # we compute the gradient of the input picture wrt this loss\n    grads \u003d K.gradients(loss, input_img)[0]\n\n    # normalization trick: we normalize the gradient\n    grads \u003d normalize(grads)\n\n    # this function returns the loss and grads given the input picture\n    iterate \u003d K.function([input_img], [loss, grads])\n\n    # step size for gradient ascent\n    step \u003d 1.\n\n    # we start from a gray image with some random noise\n    if K.image_data_format() \u003d\u003d \u0027channels_first\u0027:\n        input_img_data \u003d np.random.random((1, 3, img_width, img_height))\n    else:\n        input_img_data \u003d np.random.random((1, img_width, img_height, 3))\n    input_img_data \u003d (input_img_data - 0.5) * 20 + 128\n\n    # we run gradient ascent for 20 steps\n    for i in range(20):\n        loss_value, grads_value \u003d iterate([input_img_data])\n        input_img_data +\u003d grads_value * step\n\n        print(\u0027Current loss value:\u0027, loss_value)\n        if loss_value \u003c\u003d 0.:\n            # some filters get stuck to 0, we can skip them\n            break\n\n    # decode the resulting input image\n    if loss_value \u003e 0:\n        img \u003d deprocess_image(input_img_data[0])\n        kept_filters.append((img, loss_value))\n    end_time \u003d time.time()\n    print(\u0027Filter %d processed in %ds\u0027 % (filter_index, end_time - start_time))\n\n# we will stich the best 64 filters on a 8 x 8 grid.\nn \u003d 8\n\n# the filters that have the highest loss are assumed to be better-looking.\n# we will only keep the top 64 filters.\nkept_filters.sort(key\u003dlambda x: x[1], reverse\u003dTrue)\nkept_filters \u003d kept_filters[:n * n]\n\n# build a black picture with enough space for\n# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\nmargin \u003d 5\nwidth \u003d n * img_width + (n - 1) * margin\nheight \u003d n * img_height + (n - 1) * margin\nstitched_filters \u003d np.zeros((width, height, 3))\n\n# fill the picture with our saved filters\nfor i in range(n):\n    for j in range(n):\n        img, loss \u003d kept_filters[i * n + j]\n        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] \u003d img\n\n# save the result to disk\nimsave(\u0027stitched_filters_%dx%d.png\u0027 % (n, n), stitched_filters)",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 19, 2018 12:42:39 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516024151321_-1261517095",
      "id": "20180115-134911_733254260_q_67DDKDEJHD1516024150",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Model loaded.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\ninput_4 (InputLayer)         (None, None, None, 3)     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n(?, ?, ?, 3)\nProcessing filter 0\nCurrent loss value: 12.6086\nCurrent loss value: 24.5003\nCurrent loss value: 39.1464\nCurrent loss value: 65.5033\nCurrent loss value: 89.0018\nCurrent loss value: 106.07\nCurrent loss value: 128.133\nCurrent loss value: 152.586\nCurrent loss value: 174.269\nCurrent loss value: 196.97\nCurrent loss value: 217.705\nCurrent loss value: 238.869\nCurrent loss value: 261.123\nCurrent loss value: 279.529\nCurrent loss value: 303.223\nCurrent loss value: 324.813\nCurrent loss value: 346.666\nCurrent loss value: 368.597\nCurrent loss value: 388.04\nCurrent loss value: 414.33\nFilter 0 processed in 1s\nProcessing filter 1\nCurrent loss value: 0.0\nFilter 1 processed in 0s\nProcessing filter 2\nCurrent loss value: 8.90846\nCurrent loss value: 28.6092\nCurrent loss value: 64.9427\nCurrent loss value: 101.214\nCurrent loss value: 134.682\nCurrent loss value: 166.856\nCurrent loss value: 202.722\nCurrent loss value: 226.794\nCurrent loss value: 259.136\nCurrent loss value: 285.731\nCurrent loss value: 314.531\nCurrent loss value: 335.667\nCurrent loss value: 369.687\nCurrent loss value: 395.357\nCurrent loss value: 427.358\nCurrent loss value: 454.463\nCurrent loss value: 486.139\nCurrent loss value: 518.191\nCurrent loss value: 542.463\nCurrent loss value: 571.091\nFilter 2 processed in 1s\nProcessing filter 3\nCurrent loss value: 13.6834\nCurrent loss value: 42.129\nCurrent loss value: 121.632\nCurrent loss value: 205.747\nCurrent loss value: 293.5\nCurrent loss value: 369.801\nCurrent loss value: 435.782\nCurrent loss value: 497.67\nCurrent loss value: 561.87\nCurrent loss value: 614.021\nCurrent loss value: 668.317\nCurrent loss value: 717.794\nCurrent loss value: 764.228\nCurrent loss value: 808.007\nCurrent loss value: 853.606\nCurrent loss value: 897.263\nCurrent loss value: 941.382\nCurrent loss value: 988.657\nCurrent loss value: 1034.2\nCurrent loss value: 1075.86\nFilter 3 processed in 1s\nProcessing filter 4\nCurrent loss value: 9.41126\nCurrent loss value: 44.1892\nCurrent loss value: 95.1339\nCurrent loss value: 146.177\nCurrent loss value: 198.77\nCurrent loss value: 250.52\nCurrent loss value: 294.518\nCurrent loss value: 337.326\nCurrent loss value: 385.53\nCurrent loss value: 428.431\nCurrent loss value: 469.026\nCurrent loss value: 516.629\nCurrent loss value: 561.855\nCurrent loss value: 606.819\nCurrent loss value: 650.984\nCurrent loss value: 696.251\nCurrent loss value: 742.154\nCurrent loss value: 790.245\nCurrent loss value: 835.227\nCurrent loss value: 876.295\nFilter 4 processed in 1s\nProcessing filter 5\nCurrent loss value: 24.3\nCurrent loss value: 45.7308\nCurrent loss value: 65.0\nCurrent loss value: 97.217\nCurrent loss value: 128.719\nCurrent loss value: 166.89\nCurrent loss value: 211.465\nCurrent loss value: 257.475\nCurrent loss value: 289.301\nCurrent loss value: 344.191\nCurrent loss value: 393.549\nCurrent loss value: 445.081\nCurrent loss value: 485.922\nCurrent loss value: 525.045\nCurrent loss value: 572.147\nCurrent loss value: 607.158\nCurrent loss value: 645.282\nCurrent loss value: 683.143\nCurrent loss value: 719.85\nCurrent loss value: 760.729\nFilter 5 processed in 1s\nProcessing filter 6\nCurrent loss value: 0.0\nFilter 6 processed in 0s\nProcessing filter 7\nCurrent loss value: 3.45895\nCurrent loss value: 9.02657\nCurrent loss value: 19.9963\nCurrent loss value: 33.7987\nCurrent loss value: 62.941\nCurrent loss value: 102.434\nCurrent loss value: 143.456\nCurrent loss value: 188.819\nCurrent loss value: 235.366\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3604718554161842664.py\", line 292, in \u003cmodule\u003e\n    exec(code)\n  File \"\u003cstdin\u003e\", line 48, in \u003cmodule\u003e\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2475, in __call__\n    **self.session_kwargs)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n    options, run_metadata)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\n    return fn(*args)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\n    status, run_metadata)\n  File \"/usr/lib/spark/python/pyspark/context.py\", line 239, in signal_handler\n    raise KeyboardInterrupt()\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3604718554161842664.py\", line 299, in \u003cmodule\u003e\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3604718554161842664.py\", line 292, in \u003cmodule\u003e\n    exec(code)\n  File \"\u003cstdin\u003e\", line 48, in \u003cmodule\u003e\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2475, in __call__\n    **self.session_kwargs)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 889, in run\n    run_metadata_ptr)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\n    options, run_metadata)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\n    return fn(*args)\n  File \"/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\n    status, run_metadata)\n  File \"/usr/lib/spark/python/pyspark/context.py\", line 239, in signal_handler\n    raise KeyboardInterrupt()\nKeyboardInterrupt\n\n"
      },
      "dateCreated": "Jan 15, 2018 1:49:11 PM",
      "dateStarted": "Jan 18, 2018 11:32:29 AM",
      "dateFinished": "Jan 18, 2018 11:32:38 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Input : Input images and filters from the VGG16 Model. which is of 128x128x3 size.\nOutput : Visualization of the filters of VGG16 in the form of image output in .png format. All the filters are stacked in a single image. 8x8 filters of 128x128 size.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 18, 2018 11:36:57 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516024439544_-2126972258",
      "id": "20180115-135359_181927136_q_67DDKDEJHD1516024150",
      "dateCreated": "Jan 15, 2018 1:53:59 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "conv_filter_visualization",
  "id": "67DDKDEJHD1516024150",
  "angularObjects": {
    "2D7M1HZP5932661518613479637:shared_process": [],
    "2D6B43M8G932661515762929145:shared_process": [],
    "2D35KXZZK932661515762929137:shared_process": []
  },
  "config": {
    "isDashboard": false
  },
  "info": {},
  "source": "FCN"
}