{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:36:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516357425830_-1654927244",
      "id": "20180119-102345_1169506047_q_24Q2VEQ9FU1516357399",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 19, 2018 10:23:45 AM",
      "dateStarted": "Jan 22, 2018 5:36:10 AM",
      "dateFinished": "Jan 22, 2018 5:36:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:36:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516357432932_-1768412846",
      "id": "20180119-102352_1430423204_q_24Q2VEQ9FU1516357399",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "theano\n"
      },
      "dateCreated": "Jan 19, 2018 10:23:52 AM",
      "dateStarted": "Jan 22, 2018 5:36:10 AM",
      "dateFinished": "Jan 22, 2018 5:36:10 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from __future__ import print_function\nfrom functools import reduce\nimport re\nimport tarfile\n\nimport numpy as np\n\nfrom keras.utils.data_utils import get_file\nfrom keras.layers.embeddings import Embedding\nfrom keras import layers\nfrom keras.layers import recurrent\nfrom keras.models import Model\nfrom keras.preprocessing.sequence import pad_sequences\n\n\ndef tokenize(sent):\n    \u0027\u0027\u0027Return the tokens of a sentence including punctuation.\n    \u003e\u003e\u003e tokenize(\u0027Bob dropped the apple. Where is the apple?\u0027)\n    [\u0027Bob\u0027, \u0027dropped\u0027, \u0027the\u0027, \u0027apple\u0027, \u0027.\u0027, \u0027Where\u0027, \u0027is\u0027, \u0027the\u0027, \u0027apple\u0027, \u0027?\u0027]\n    \u0027\u0027\u0027\n    return [x.strip() for x in re.split(\u0027(\\W+)?\u0027, sent) if x.strip()]\n\n\ndef parse_stories(lines, only_supporting\u003dFalse):\n    \u0027\u0027\u0027Parse stories provided in the bAbi tasks format\n    If only_supporting is true,\n    only the sentences that support the answer are kept.\n    \u0027\u0027\u0027\n    data \u003d []\n    story \u003d []\n    for line in lines:\n        line \u003d line.decode(\u0027utf-8\u0027).strip()\n        nid, line \u003d line.split(\u0027 \u0027, 1)\n        nid \u003d int(nid)\n        if nid \u003d\u003d 1:\n            story \u003d []\n        if \u0027\\t\u0027 in line:\n            q, a, supporting \u003d line.split(\u0027\\t\u0027)\n            q \u003d tokenize(q)\n            substory \u003d None\n            if only_supporting:\n                # Only select the related substory\n                supporting \u003d map(int, supporting.split())\n                substory \u003d [story[i - 1] for i in supporting]\n            else:\n                # Provide all the substories\n                substory \u003d [x for x in story if x]\n            data.append((substory, q, a))\n            story.append(\u0027\u0027)\n        else:\n            sent \u003d tokenize(line)\n            story.append(sent)\n    return data\n\n\ndef get_stories(f, only_supporting\u003dFalse, max_length\u003dNone):\n    \u0027\u0027\u0027Given a file name, read the file, retrieve the stories,\n    and then convert the sentences into a single story.\n    If max_length is supplied,\n    any stories longer than max_length tokens will be discarded.\n    \u0027\u0027\u0027\n    data \u003d parse_stories(f.readlines(), only_supporting\u003donly_supporting)\n    flatten \u003d lambda data: reduce(lambda x, y: x + y, data)\n    data \u003d [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) \u003c max_length]\n    return data\n\n\ndef vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n    xs \u003d []\n    xqs \u003d []\n    ys \u003d []\n    for story, query, answer in data:\n        x \u003d [word_idx[w] for w in story]\n        xq \u003d [word_idx[w] for w in query]\n        # let\u0027s not forget that index 0 is reserved\n        y \u003d np.zeros(len(word_idx) + 1)\n        y[word_idx[answer]] \u003d 1\n        xs.append(x)\n        xqs.append(xq)\n        ys.append(y)\n    return pad_sequences(xs, maxlen\u003dstory_maxlen), pad_sequences(xqs, maxlen\u003dquery_maxlen), np.array(ys)\n\nRNN \u003d recurrent.LSTM\nEMBED_HIDDEN_SIZE \u003d 50\nSENT_HIDDEN_SIZE \u003d 100\nQUERY_HIDDEN_SIZE \u003d 100\nBATCH_SIZE \u003d 32\nEPOCHS \u003d 5\nprint(\u0027RNN / Embed / Sent / Query \u003d {}, {}, {}, {}\u0027.format(RNN,\n                                                           EMBED_HIDDEN_SIZE,\n                                                           SENT_HIDDEN_SIZE,\n                                                           QUERY_HIDDEN_SIZE))\n\ntry:\n    path \u003d get_file(\u0027babi-tasks-v1-2.tar.gz\u0027, origin\u003d\u0027https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\u0027)\nexcept:\n    print(\u0027Error downloading dataset, please download it manually:\\n\u0027\n          \u0027$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n\u0027\n          \u0027$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz\u0027)\n    raise\ntar \u003d tarfile.open(path)\n# Default QA1 with 1000 samples\n# challenge \u003d \u0027tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt\u0027\n# QA1 with 10,000 samples\n# challenge \u003d \u0027tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt\u0027\n# QA2 with 1000 samples\nchallenge \u003d \u0027tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt\u0027\n# QA2 with 10,000 samples\n# challenge \u003d \u0027tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt\u0027\ntrain \u003d get_stories(tar.extractfile(challenge.format(\u0027train\u0027)))\ntest \u003d get_stories(tar.extractfile(challenge.format(\u0027test\u0027)))\n\nvocab \u003d set()\nfor story, q, answer in train + test:\n    vocab |\u003d set(story + q + [answer])\nvocab \u003d sorted(vocab)\n\n# Reserve 0 for masking via pad_sequences\nvocab_size \u003d len(vocab) + 1\nword_idx \u003d dict((c, i + 1) for i, c in enumerate(vocab))\nstory_maxlen \u003d max(map(len, (x for x, _, _ in train + test)))\nquery_maxlen \u003d max(map(len, (x for _, x, _ in train + test)))\n\nx, xq, y \u003d vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\ntx, txq, ty \u003d vectorize_stories(test, word_idx, story_maxlen, query_maxlen)\n\nprint(\u0027vocab \u003d {}\u0027.format(vocab))\nprint(\u0027x.shape \u003d {}\u0027.format(x.shape))\nprint(\u0027xq.shape \u003d {}\u0027.format(xq.shape))\nprint(\u0027y.shape \u003d {}\u0027.format(y.shape))\nprint(\u0027story_maxlen, query_maxlen \u003d {}, {}\u0027.format(story_maxlen, query_maxlen))\n\nprint(\u0027Build model...\u0027)\n\nsentence \u003d layers.Input(shape\u003d(story_maxlen,), dtype\u003d\u0027int32\u0027)\nencoded_sentence \u003d layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\nencoded_sentence \u003d layers.Dropout(0.3)(encoded_sentence)\n\nquestion \u003d layers.Input(shape\u003d(query_maxlen,), dtype\u003d\u0027int32\u0027)\nencoded_question \u003d layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\nencoded_question \u003d layers.Dropout(0.3)(encoded_question)\nencoded_question \u003d RNN(EMBED_HIDDEN_SIZE)(encoded_question)\nencoded_question \u003d layers.RepeatVector(story_maxlen)(encoded_question)\n\nmerged \u003d layers.add([encoded_sentence, encoded_question])\nmerged \u003d RNN(EMBED_HIDDEN_SIZE)(merged)\nmerged \u003d layers.Dropout(0.3)(merged)\npreds \u003d layers.Dense(vocab_size, activation\u003d\u0027softmax\u0027)(merged)\n\nmodel \u003d Model([sentence, question], preds)\nmodel.compile(optimizer\u003d\u0027adam\u0027,\n              loss\u003d\u0027categorical_crossentropy\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\n\nprint(\u0027Training\u0027)\nmodel.fit([x, xq], y,\n          batch_size\u003dBATCH_SIZE,\n          epochs\u003dEPOCHS,\n          validation_split\u003d0.05)\nloss, acc \u003d model.evaluate([tx, txq], ty,\n                           batch_size\u003dBATCH_SIZE)\nprint(\u0027Test loss / test accuracy \u003d {:.4f} / {:.4f}\u0027.format(loss, acc))",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:36:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516019341729_-919397811",
      "id": "20180115-122901_1736191046_q_24Q2VEQ9FU1516357399",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "RNN / Embed / Sent / Query \u003d \u003cclass \u0027keras.layers.recurrent.LSTM\u0027\u003e, 50, 100, 100\n/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n  return _compile(pattern, flags).split(string, maxsplit)\nvocab \u003d [\u0027.\u0027, \u0027?\u0027, \u0027Daniel\u0027, \u0027John\u0027, \u0027Mary\u0027, \u0027Sandra\u0027, \u0027Where\u0027, \u0027apple\u0027, \u0027back\u0027, \u0027bathroom\u0027, \u0027bedroom\u0027, \u0027discarded\u0027, \u0027down\u0027, \u0027dropped\u0027, \u0027football\u0027, \u0027garden\u0027, \u0027got\u0027, \u0027grabbed\u0027, \u0027hallway\u0027, \u0027is\u0027, \u0027journeyed\u0027, \u0027kitchen\u0027, \u0027left\u0027, \u0027milk\u0027, \u0027moved\u0027, \u0027office\u0027, \u0027picked\u0027, \u0027put\u0027, \u0027the\u0027, \u0027there\u0027, \u0027to\u0027, \u0027took\u0027, \u0027travelled\u0027, \u0027up\u0027, \u0027went\u0027]\nx.shape \u003d (1000, 552)\nxq.shape \u003d (1000, 5)\ny.shape \u003d (1000, 36)\nstory_maxlen, query_maxlen \u003d 552, 5\nBuild model...\n/usr/lib/a-4.2.0-py-3.5.3-dl-gpu-full/lib/python3.5/site-packages/keras/layers/recurrent.py:1993: UserWarning: RNN dropout is no longer supported with the Theano backend due to technical limitations. You can either set `dropout` and `recurrent_dropout` to 0, or use the TensorFlow backend.\n  \u0027RNN dropout is no longer supported with the Theano backend \u0027\nTraining\nTrain on 950 samples, validate on 50 samples\nEpoch 1/5\n\n 32/950 [\u003e.............................] - ETA: 19s - loss: 3.5846 - acc: 0.0000e+00\n\n 64/950 [\u003d\u003e............................] - ETA: 18s - loss: 3.5816 - acc: 0.0156    \n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 18s - loss: 3.5783 - acc: 0.0729\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 17s - loss: 3.5757 - acc: 0.0625\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 16s - loss: 3.5721 - acc: 0.0813\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 16s - loss: 3.5680 - acc: 0.0781\n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 15s - loss: 3.5636 - acc: 0.0848\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 14s - loss: 3.5583 - acc: 0.1016\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 14s - loss: 3.5536 - acc: 0.1042\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 13s - loss: 3.5476 - acc: 0.1125\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 12s - loss: 3.5407 - acc: 0.1193\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 12s - loss: 3.5320 - acc: 0.1250\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 11s - loss: 3.5238 - acc: 0.1274\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 10s - loss: 3.5136 - acc: 0.1272\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 9s - loss: 3.5004 - acc: 0.1292 \n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 9s - loss: 3.4860 - acc: 0.1270\n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 8s - loss: 3.4713 - acc: 0.1287\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 7s - loss: 3.4554 - acc: 0.1285\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 7s - loss: 3.4342 - acc: 0.1266\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 6s - loss: 3.4056 - acc: 0.1281\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 5s - loss: 3.3753 - acc: 0.1295\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 5s - loss: 3.3433 - acc: 0.1321\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 4s - loss: 3.3060 - acc: 0.1345\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 3s - loss: 3.2744 - acc: 0.1380\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 3s - loss: 3.2396 - acc: 0.1425\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 2s - loss: 3.2106 - acc: 0.1418\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 3.1846 - acc: 0.1412\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 1s - loss: 3.1550 - acc: 0.1473\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 3.1238 - acc: 0.1498\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 21s 22ms/step - loss: 3.1080 - acc: 0.1484 - val_loss: 2.1849 - val_acc: 0.3000\n\nEpoch 2/5\n\n 32/950 [\u003e.............................] - ETA: 19s - loss: 2.5545 - acc: 0.0625\n\n 64/950 [\u003d\u003e............................] - ETA: 18s - loss: 2.3713 - acc: 0.1719\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 18s - loss: 2.2793 - acc: 0.1875\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 17s - loss: 2.2549 - acc: 0.2031\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 16s - loss: 2.2004 - acc: 0.2250\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 16s - loss: 2.1804 - acc: 0.2240\n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 15s - loss: 2.1926 - acc: 0.2054\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 14s - loss: 2.1746 - acc: 0.2070\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 14s - loss: 2.1731 - acc: 0.1944\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 13s - loss: 2.1771 - acc: 0.1906\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 12s - loss: 2.1703 - acc: 0.1875\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 12s - loss: 2.1711 - acc: 0.1823\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 11s - loss: 2.1581 - acc: 0.1827\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 10s - loss: 2.1546 - acc: 0.1763\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 10s - loss: 2.1518 - acc: 0.1771\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 9s - loss: 2.1446 - acc: 0.1758 \n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 8s - loss: 2.1394 - acc: 0.1783\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 8s - loss: 2.1264 - acc: 0.1840\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 7s - loss: 2.1246 - acc: 0.1809\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 6s - loss: 2.1146 - acc: 0.1812\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 5s - loss: 2.1090 - acc: 0.1786\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 5s - loss: 2.1042 - acc: 0.1747\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 4s - loss: 2.0954 - acc: 0.1766\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 3s - loss: 2.0883 - acc: 0.1745\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 3s - loss: 2.0764 - acc: 0.1750\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 2s - loss: 2.0715 - acc: 0.1743\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 2.0741 - acc: 0.1725\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 1s - loss: 2.0653 - acc: 0.1775\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 2.0542 - acc: 0.1832\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 21s 22ms/step - loss: 2.0513 - acc: 0.1821 - val_loss: 1.8863 - val_acc: 0.0600\n\nEpoch 3/5\n\n 32/950 [\u003e.............................] - ETA: 19s - loss: 2.0101 - acc: 0.1250\n\n 64/950 [\u003d\u003e............................] - ETA: 18s - loss: 1.9968 - acc: 0.1562\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 18s - loss: 2.0075 - acc: 0.1458\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 17s - loss: 2.0008 - acc: 0.1328\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 17s - loss: 1.9618 - acc: 0.1750\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 16s - loss: 1.9489 - acc: 0.1823\n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 15s - loss: 1.9411 - acc: 0.2009\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 15s - loss: 1.9213 - acc: 0.1914\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 14s - loss: 1.9332 - acc: 0.1840\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 13s - loss: 1.9158 - acc: 0.1969\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 13s - loss: 1.9214 - acc: 0.1989\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 12s - loss: 1.9349 - acc: 0.1875\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 11s - loss: 1.9356 - acc: 0.1875\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 10s - loss: 1.9432 - acc: 0.1786\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 10s - loss: 1.9369 - acc: 0.1771\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 9s - loss: 1.9323 - acc: 0.1777 \n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 8s - loss: 1.9354 - acc: 0.1710\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 8s - loss: 1.9267 - acc: 0.1736\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 7s - loss: 1.9230 - acc: 0.1743\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 6s - loss: 1.9203 - acc: 0.1766\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 6s - loss: 1.9130 - acc: 0.1815\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 5s - loss: 1.9118 - acc: 0.1804\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 4s - loss: 1.9063 - acc: 0.1793\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 3s - loss: 1.9096 - acc: 0.1810\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 3s - loss: 1.9169 - acc: 0.1775\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 2s - loss: 1.9204 - acc: 0.1767\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 1.9209 - acc: 0.1771\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 1s - loss: 1.9270 - acc: 0.1741\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 1.9250 - acc: 0.1756\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 21s 22ms/step - loss: 1.9232 - acc: 0.1747 - val_loss: 1.8323 - val_acc: 0.0600\n\nEpoch 4/5\n\n 32/950 [\u003e.............................] - ETA: 20s - loss: 1.8643 - acc: 0.1562\n\n 64/950 [\u003d\u003e............................] - ETA: 19s - loss: 1.8646 - acc: 0.1562\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 18s - loss: 1.8982 - acc: 0.1562\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 17s - loss: 1.8976 - acc: 0.1328\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 17s - loss: 1.8705 - acc: 0.1500\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 16s - loss: 1.8882 - acc: 0.1562\n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 15s - loss: 1.8989 - acc: 0.1518\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 15s - loss: 1.9011 - acc: 0.1641\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 14s - loss: 1.9149 - acc: 0.1597\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 13s - loss: 1.9277 - acc: 0.1500\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 13s - loss: 1.9240 - acc: 0.1506\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 12s - loss: 1.9249 - acc: 0.1458\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 11s - loss: 1.9248 - acc: 0.1514\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 11s - loss: 1.9169 - acc: 0.1518\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 10s - loss: 1.9197 - acc: 0.1521\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 9s - loss: 1.9178 - acc: 0.1465 \n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 8s - loss: 1.9052 - acc: 0.1544\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 8s - loss: 1.8984 - acc: 0.1562\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 7s - loss: 1.9006 - acc: 0.1595\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 6s - loss: 1.9033 - acc: 0.1578\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 6s - loss: 1.8994 - acc: 0.1652\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 5s - loss: 1.9063 - acc: 0.1591\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 4s - loss: 1.9060 - acc: 0.1617\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 4s - loss: 1.9015 - acc: 0.1654\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 3s - loss: 1.9002 - acc: 0.1688\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 2s - loss: 1.8990 - acc: 0.1707\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 1.8987 - acc: 0.1748\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 1s - loss: 1.9017 - acc: 0.1730\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 1.9019 - acc: 0.1746\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 21s 23ms/step - loss: 1.9065 - acc: 0.1737 - val_loss: 1.8255 - val_acc: 0.0600\n\nEpoch 5/5\n\n 32/950 [\u003e.............................] - ETA: 20s - loss: 1.8756 - acc: 0.1250\n\n 64/950 [\u003d\u003e............................] - ETA: 19s - loss: 1.9122 - acc: 0.0938\n\n 96/950 [\u003d\u003d\u003e...........................] - ETA: 18s - loss: 1.9030 - acc: 0.1146\n\n128/950 [\u003d\u003d\u003d\u003e..........................] - ETA: 17s - loss: 1.9173 - acc: 0.1406\n\n160/950 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 17s - loss: 1.9275 - acc: 0.1437\n\n192/950 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 16s - loss: 1.9200 - acc: 0.1406\n\n224/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 15s - loss: 1.9335 - acc: 0.1384\n\n256/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 15s - loss: 1.9181 - acc: 0.1445\n\n288/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 14s - loss: 1.9086 - acc: 0.1458\n\n320/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 13s - loss: 1.8976 - acc: 0.1500\n\n352/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 13s - loss: 1.8921 - acc: 0.1562\n\n384/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 12s - loss: 1.9032 - acc: 0.1510\n\n416/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 11s - loss: 1.9039 - acc: 0.1514\n\n448/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 10s - loss: 1.8971 - acc: 0.1674\n\n480/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 10s - loss: 1.8990 - acc: 0.1667\n\n512/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 9s - loss: 1.8996 - acc: 0.1680 \n\n544/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 8s - loss: 1.9019 - acc: 0.1636\n\n576/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 8s - loss: 1.9016 - acc: 0.1649\n\n608/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 7s - loss: 1.8982 - acc: 0.1711\n\n640/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 6s - loss: 1.9010 - acc: 0.1656\n\n672/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 6s - loss: 1.9008 - acc: 0.1711\n\n704/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 5s - loss: 1.9018 - acc: 0.1719\n\n736/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 4s - loss: 1.8983 - acc: 0.1739\n\n768/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 3s - loss: 1.8989 - acc: 0.1732\n\n800/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 3s - loss: 1.8979 - acc: 0.1713\n\n832/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 2s - loss: 1.8985 - acc: 0.1743\n\n864/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 1s - loss: 1.8993 - acc: 0.1736\n\n896/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 1s - loss: 1.9025 - acc: 0.1730\n\n928/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 1.9033 - acc: 0.1703\n\n950/950 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 21s 22ms/step - loss: 1.9073 - acc: 0.1705 - val_loss: 1.8277 - val_acc: 0.0600\n\n\n  32/1000 [..............................] - ETA: 5s\n\n  64/1000 [\u003e.............................] - ETA: 4s\n\n  96/1000 [\u003d\u003e............................] - ETA: 4s\n\n 128/1000 [\u003d\u003d\u003e...........................] - ETA: 4s\n\n 160/1000 [\u003d\u003d\u003d\u003e..........................] - ETA: 4s\n\n 192/1000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 4s\n\n 224/1000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 4s\n\n 256/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 3s\n\n 288/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 3s\n\n 320/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 3s\n\n 352/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 3s\n\n 384/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 3s\n\n 416/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 3s\n\n 448/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 2s\n\n 480/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 2s\n\n 512/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 2s\n\n 544/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 2s\n\n 576/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 2s\n\n 608/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 2s\n\n 640/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 1s\n\n 672/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 1s\n\n 704/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 1s\n\n 736/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 1s\n\n 768/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 1s\n\n 800/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 1s\n\n 832/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s\n\n 864/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s\n\n 896/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s\n\n 928/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s\n\n 960/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s\n\n 992/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s\n\n1000/1000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 5s 5ms/step\n\nTest loss / test accuracy \u003d 1.8331 / 0.1870\n"
      },
      "dateCreated": "Jan 15, 2018 12:29:01 PM",
      "dateStarted": "Jan 22, 2018 5:36:10 AM",
      "dateFinished": "Jan 22, 2018 5:39:12 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Model :- RNN.\nInput :- Facebook bAbI dataset. Contains stories etc. Contains 10000 training stories.\nThe file format for each task is as follows:\nID text\nID text\nID text\nID question[tab]answer[tab]supporting fact IDS.\n...\n\nThe IDs for a given \"story\" start at 1 and increase.\nWhen the IDs in a file reset back to 1 you can consider the following sentences as a new \"story\".\n\nOutput :- Accuracy which is calculated as : questions are asked based on the stories and its accuracy is measured. Real number in the range 0-1.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:36:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516019440778_-1534706536",
      "id": "20180115-123040_1534675501_q_24Q2VEQ9FU1516357399",
      "dateCreated": "Jan 15, 2018 12:30:40 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516599370329_816506645",
      "id": "20180122-053610_191919234_q_24Q2VEQ9FU1516357399",
      "dateCreated": "Jan 22, 2018 5:36:10 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "bAbI_RNN",
  "id": "24Q2VEQ9FU1516357399",
  "angularObjects": {
    "2D7M1HZP5932661518613479637:shared_process": [],
    "2D6B43M8G932661515762929145:shared_process": [],
    "2D35KXZZK932661515762929137:shared_process": []
  },
  "config": {
    "isDashboard": false
  },
  "info": {},
  "source": "FCN"
}