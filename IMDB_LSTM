{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027\nos.environ[\u0027MKL_THREADING_LAYER\u0027] \u003d \"GNU\"",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 7:19:46 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516356459755_141305550",
      "id": "20180119-100739_1636234897_q_1KCQRXXU2P1527183060",
      "dateCreated": "Jan 19, 2018 10:07:39 AM",
      "dateSubmitted": "May 24, 2018 5:31:36 PM",
      "dateStarted": "May 24, 2018 5:31:49 PM",
      "dateFinished": "May 24, 2018 5:32:10 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "dateUpdated": "Jan 19, 2018 10:07:58 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516356462191_-1327265677",
      "id": "20180119-100742_1983015191_q_1KCQRXXU2P1527183060",
      "dateCreated": "Jan 19, 2018 10:07:42 AM",
      "dateSubmitted": "May 24, 2018 5:31:49 PM",
      "dateStarted": "May 24, 2018 5:32:10 PM",
      "dateFinished": "May 24, 2018 5:32:11 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\"\"\"\n    The IMDB dataset consists of 25000 reviews in the training batch as well as the testing batch, labelled by sentiment either positive or negative. Reviews have been          preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for       instance the integer \"3\" encodes the 3rd most frequent word in the data. \n\n    The dataset is divided into one training batch with 25000 samples and one test batch with 25000 samples.\n    \n    Each batch contains a dictionary with the following elements:-\n    \n    data -- an array of 25000 lists for each training as well as testing batch. Each element in the list has different length and is a review encoded as a sequence of word      indexes(integers).\n    labels -- an array of 25000 numbers either 0 or 1 for both training as well as testing batch. The number at index i indicates the label of the ith image in the              array data.\n\"\"\"\n\n# importing necessary libraries for the neural network such as keras and its layer types\n\nfrom __future__ import print_function\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding\nfrom keras.layers import LSTM\nfrom keras.datasets import imdb\n\n# setting the parameters used in the model such as batch_size, max number of samples, etc.\nmax_features \u003d 20000\nmaxlen \u003d 80  # cut texts after this number of words (among top max_features most common words)\nbatch_size \u003d 32\n\nprint(\u0027Loading data...\u0027)\n\n# loading the data, shuffled and split between train and test sets.\n(x_train, y_train), (x_test, y_test) \u003d imdb.load_data(num_words\u003dmax_features)\nprint(len(x_train), \u0027train sequences\u0027)\nprint(len(x_test), \u0027test sequences\u0027)\n\nprint(\u0027Pad sequences (samples x time)\u0027)\n\n# padding the training and testing data with zeroes.\nx_train \u003d sequence.pad_sequences(x_train, maxlen\u003dmaxlen)\nx_test \u003d sequence.pad_sequences(x_test, maxlen\u003dmaxlen)\nprint(\u0027x_train shape:\u0027, x_train.shape)\nprint(\u0027x_test shape:\u0027, x_test.shape)\n\nprint(\u0027Build model...\u0027)\n\n# building the sequential LSTM model.\nmodel \u003d Sequential()\n\n# adding an embedding layer to map the vocabulary into its embedding vector representation.\nmodel.add(Embedding(max_features, 128))\n\n# adding a LSTM layer with 128 nodes and 0.2 as dropout and recurrent_dropout for avoiding overfitting of the model.\nmodel.add(LSTM(128, dropout\u003d0.2, recurrent_dropout\u003d0.2))\n\n# adding a dense layer with one output node and \u0027sigmoid\u0027 as activation function.\nmodel.add(Dense(1, activation\u003d\u0027sigmoid\u0027))\n\n# compiling the model. Using binary_crossentropy since the classes are only two. Using \u0027adam\u0027 optimizer.\nmodel.compile(loss\u003d\u0027binary_crossentropy\u0027,\n              optimizer\u003d\u0027adam\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\n\nprint(\u0027Train...\u0027)\n# training the model on training data.\nmodel.fit(x_train, y_train,\n          batch_size\u003dbatch_size,\n          epochs\u003d2,\n          validation_data\u003d(x_test, y_test))\n          \n# finally evaluating and printing the accuracy of the trained model.\nscore, acc \u003d model.evaluate(x_test, y_test,\n                            batch_size\u003dbatch_size)\nprint(\u0027Test score:\u0027, score)\nprint(\u0027Test accuracy:\u0027, acc)",
      "dateUpdated": "Jan 19, 2018 10:07:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1515754743769_1684834477",
      "id": "20180112-105903_1879668811_q_1KCQRXXU2P1527183060",
      "dateCreated": "Jan 12, 2018 10:59:03 AM",
      "dateSubmitted": "May 24, 2018 5:32:11 PM",
      "dateStarted": "May 24, 2018 5:32:11 PM",
      "dateFinished": "May 24, 2018 5:32:11 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Jan 19, 2018 10:07:59 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1515764742526_1613918012",
      "id": "20180112-134542_1125976185_q_1KCQRXXU2P1527183060",
      "dateCreated": "Jan 12, 2018 1:45:42 PM",
      "dateSubmitted": "May 24, 2018 5:32:11 PM",
      "dateStarted": "May 24, 2018 5:32:11 PM",
      "dateFinished": "May 24, 2018 5:32:11 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "IMDB_LSTM",
  "id": "1KCQRXXU2P1527183060",
  "angularObjects": {
    "2DEK3QV851090031527168688484:shared_process": [],
    "2DENTX6JV1090031527168688466:shared_process": [],
    "2DH76KQ8R1090031527183075233:shared_process": [],
    "2DDED8P751090031527168688477:shared_process": [],
    "2DDBWFX441090031527168688480:shared_process": []
  },
  "config": {
    "isDashboard": false,
    "defaultLang": "pyspark"
  },
  "info": {},
  "source": "FCN"
}