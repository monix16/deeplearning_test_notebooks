{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda/lib64,dnn.include_path\u003d/usr/local/cuda/include/\u0027\nos.environ[\u0027MKL_THREADING_LAYER\u0027] \u003d \"GNU\"",
      "user": "prashantp@qubole.com",
      "dateUpdated": "May 25, 2018 7:19:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357627177_536308042",
      "id": "20180119-102707_1758697403_q_7XXGBY8VCK1527182754",
      "dateCreated": "Jan 19, 2018 10:27:07 AM",
      "dateSubmitted": "May 24, 2018 5:26:29 PM",
      "dateStarted": "May 24, 2018 5:26:44 PM",
      "dateFinished": "May 24, 2018 5:27:10 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "dateUpdated": "Jan 22, 2018 6:21:40 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357634095_1974130006",
      "id": "20180119-102714_1648087774_q_7XXGBY8VCK1527182754",
      "dateCreated": "Jan 19, 2018 10:27:14 AM",
      "dateSubmitted": "May 24, 2018 5:26:44 PM",
      "dateStarted": "May 24, 2018 5:27:10 PM",
      "dateFinished": "May 24, 2018 5:27:11 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from keras.models import Sequential\nfrom keras.layers.convolutional import Conv3D\nfrom keras.layers.convolutional_recurrent import ConvLSTM2D\nfrom keras.layers.normalization import BatchNormalization\nimport numpy as np\nimport pylab as plt\n\n# We create a layer which take as input movies of shape\n# (n_frames, width, height, channels) and returns a movie\n# of identical shape.\n\nseq \u003d Sequential()\nseq.add(ConvLSTM2D(filters\u003d40, kernel_size\u003d(3, 3),\n                   input_shape\u003d(None, 40, 40, 1),\n                   padding\u003d\u0027same\u0027, return_sequences\u003dTrue))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters\u003d40, kernel_size\u003d(3, 3),\n                   padding\u003d\u0027same\u0027, return_sequences\u003dTrue))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters\u003d40, kernel_size\u003d(3, 3),\n                   padding\u003d\u0027same\u0027, return_sequences\u003dTrue))\nseq.add(BatchNormalization())\n\nseq.add(ConvLSTM2D(filters\u003d40, kernel_size\u003d(3, 3),\n                   padding\u003d\u0027same\u0027, return_sequences\u003dTrue))\nseq.add(BatchNormalization())\n\nseq.add(Conv3D(filters\u003d1, kernel_size\u003d(3, 3, 3),\n               activation\u003d\u0027sigmoid\u0027,\n               padding\u003d\u0027same\u0027, data_format\u003d\u0027channels_last\u0027))\nseq.compile(loss\u003d\u0027binary_crossentropy\u0027, optimizer\u003d\u0027adadelta\u0027)\n\n\n# Artificial data generation:\n# Generate movies with 3 to 7 moving squares inside.\n# The squares are of shape 1x1 or 2x2 pixels,\n# which move linearly over time.\n# For convenience we first create movies with bigger width and height (80x80)\n# and at the end we select a 40x40 window.\n\ndef generate_movies(n_samples\u003d1200, n_frames\u003d15):\n    row \u003d 80\n    col \u003d 80\n    noisy_movies \u003d np.zeros((n_samples, n_frames, row, col, 1), dtype\u003dnp.float)\n    shifted_movies \u003d np.zeros((n_samples, n_frames, row, col, 1),\n                              dtype\u003dnp.float)\n\n    for i in range(n_samples):\n        # Add 3 to 7 moving squares\n        n \u003d np.random.randint(3, 8)\n\n        for j in range(n):\n            # Initial position\n            xstart \u003d np.random.randint(20, 60)\n            ystart \u003d np.random.randint(20, 60)\n            # Direction of motion\n            directionx \u003d np.random.randint(0, 3) - 1\n            directiony \u003d np.random.randint(0, 3) - 1\n\n            # Size of the square\n            w \u003d np.random.randint(2, 4)\n\n            for t in range(n_frames):\n                x_shift \u003d xstart + directionx * t\n                y_shift \u003d ystart + directiony * t\n                noisy_movies[i, t, x_shift - w: x_shift + w,\n                             y_shift - w: y_shift + w, 0] +\u003d 1\n\n                # Make it more robust by adding noise.\n                # The idea is that if during inference,\n                # the value of the pixel is not exactly one,\n                # we need to train the network to be robust and still\n                # consider it as a pixel belonging to a square.\n                if np.random.randint(0, 2):\n                    noise_f \u003d (-1)**np.random.randint(0, 2)\n                    noisy_movies[i, t,\n                                 x_shift - w - 1: x_shift + w + 1,\n                                 y_shift - w - 1: y_shift + w + 1,\n                                 0] +\u003d noise_f * 0.1\n\n                # Shift the ground truth by 1\n                x_shift \u003d xstart + directionx * (t + 1)\n                y_shift \u003d ystart + directiony * (t + 1)\n                shifted_movies[i, t, x_shift - w: x_shift + w,\n                               y_shift - w: y_shift + w, 0] +\u003d 1\n\n    # Cut to a 40x40 window\n    noisy_movies \u003d noisy_movies[::, ::, 20:60, 20:60, ::]\n    shifted_movies \u003d shifted_movies[::, ::, 20:60, 20:60, ::]\n    noisy_movies[noisy_movies \u003e\u003d 1] \u003d 1\n    shifted_movies[shifted_movies \u003e\u003d 1] \u003d 1\n    return noisy_movies, shifted_movies\n\n# Train the network\nnoisy_movies, shifted_movies \u003d generate_movies(n_samples\u003d1200)\nseq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size\u003d10,\n        epochs\u003d1, validation_split\u003d0.05)\n\n# Testing the network on one movie\n# feed it with the first 7 positions and then\n# predict the new positions\nwhich \u003d 1004\ntrack \u003d noisy_movies[which][:7, ::, ::, ::]\n\nfor j in range(16):\n    new_pos \u003d seq.predict(track[np.newaxis, ::, ::, ::, ::])\n    new \u003d new_pos[::, -1, ::, ::, ::]\n    track \u003d np.concatenate((track, new), axis\u003d0)\n\n\n# And then compare the predictions\n# to the ground truth\ntrack2 \u003d noisy_movies[which][::, ::, ::, ::]\nfor i in range(15):\n    fig \u003d plt.figure(figsize\u003d(10, 5))\n\n    ax \u003d fig.add_subplot(121)\n\n    if i \u003e\u003d 7:\n        ax.text(1, 3, \u0027Predictions !\u0027, fontsize\u003d20, color\u003d\u0027w\u0027)\n    else:\n        ax.text(1, 3, \u0027Initial trajectory\u0027, fontsize\u003d20)\n\n    toplot \u003d track[i, ::, ::, 0]\n\n    plt.imshow(toplot)\n    ax \u003d fig.add_subplot(122)\n    plt.text(1, 3, \u0027Ground truth\u0027, fontsize\u003d20)\n\n    toplot \u003d track2[i, ::, ::, 0]\n    if i \u003e\u003d 2:\n        toplot \u003d shifted_movies[which][i - 1, ::, ::, 0]\n\n    plt.imshow(toplot)\n    plt.savefig(\u0027%i_animate.png\u0027 % (i + 1))",
      "dateUpdated": "Jan 22, 2018 6:21:40 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516024205811_957622615",
      "id": "20180115-135005_1535390504_q_7XXGBY8VCK1527182754",
      "dateCreated": "Jan 15, 2018 1:50:05 PM",
      "dateSubmitted": "May 24, 2018 5:27:10 PM",
      "dateStarted": "May 24, 2018 5:27:11 PM",
      "dateFinished": "May 24, 2018 5:27:12 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Input : Movies are created Artificially using data generation. Movies with 3 to 7 moving squares inside a window of size 80x80. 1200 in total.\nOutput : Predicted position in the form of images in .png format. 15 images.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 6:21:40 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516096457054_-588014023",
      "id": "20180116-095417_653813138_q_7XXGBY8VCK1527182754",
      "dateCreated": "Jan 16, 2018 9:54:17 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Jan 22, 2018 6:21:40 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516366882927_-162875264",
      "id": "20180119-130122_1092789159_q_7XXGBY8VCK1527182754",
      "dateCreated": "Jan 19, 2018 1:01:22 PM",
      "dateSubmitted": "May 24, 2018 5:27:12 PM",
      "dateStarted": "May 24, 2018 5:27:12 PM",
      "dateFinished": "May 24, 2018 5:27:12 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "conv_lstm",
  "id": "7XXGBY8VCK1527182754",
  "angularObjects": {
    "2DE6MWTYB1090031527182769810:shared_process": [],
    "2DEK3QV851090031527168688484:shared_process": [],
    "2DENTX6JV1090031527168688466:shared_process": [],
    "2DDED8P751090031527168688477:shared_process": [],
    "2DDBWFX441090031527168688480:shared_process": []
  },
  "config": {
    "isDashboard": false,
    "defaultLang": "pyspark"
  },
  "info": {},
  "source": "FCN"
}