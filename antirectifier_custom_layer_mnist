{
  "paragraphs": [
    {
      "text": "os.environ[\"KERAS_BACKEND\"] \u003d \"theano\"\nos.environ[\u0027THEANO_FLAGS\u0027] \u003d \u0027floatX\u003dfloat32,device\u003dcuda,dnn.library_path\u003d/usr/local/cuda-8.0/lib64,dnn.include_path\u003d/usr/local/cuda-8.0/include/\u0027",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:23:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357263866_-225395733",
      "id": "20180119-102103_1323710332_q_ZGTJCVWT3Z1516357240",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 19, 2018 10:21:03 AM",
      "dateStarted": "Jan 22, 2018 5:23:14 AM",
      "dateFinished": "Jan 22, 2018 5:23:14 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "# Confirming backend is changed to Theano\nfrom __future__ import print_function\nimport keras\nfrom keras import backend as K\nprint(K.backend())",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:23:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516357259050_-1202288515",
      "id": "20180119-102059_947873015_q_ZGTJCVWT3Z1516357240",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "theano\n"
      },
      "dateCreated": "Jan 19, 2018 10:20:59 AM",
      "dateStarted": "Jan 22, 2018 5:23:14 AM",
      "dateFinished": "Jan 22, 2018 5:23:14 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.datasets import mnist\nfrom keras import backend as K\n\n\nclass Antirectifier(layers.Layer):\n    \u0027\u0027\u0027This is the combination of a sample-wise\n    L2 normalization with the concatenation of the\n    positive part of the input with the negative part\n    of the input. The result is a tensor of samples that are\n    twice as large as the input samples.\n    It can be used in place of a ReLU.\n    # Input shape\n        2D tensor of shape (samples, n)\n    # Output shape\n        2D tensor of shape (samples, 2*n)\n    # Theoretical justification\n        When applying ReLU, assuming that the distribution\n        of the previous output is approximately centered around 0.,\n        you are discarding half of your input. This is inefficient.\n        Antirectifier allows to return all-positive outputs like ReLU,\n        without discarding any data.\n        Tests on MNIST show that Antirectifier allows to train networks\n        with twice less parameters yet with comparable\n        classification accuracy as an equivalent ReLU-based network.\n    \u0027\u0027\u0027\n\n    def compute_output_shape(self, input_shape):\n        shape \u003d list(input_shape)\n        assert len(shape) \u003d\u003d 2  # only valid for 2D tensors\n        shape[-1] *\u003d 2\n        return tuple(shape)\n\n    def call(self, inputs):\n        inputs -\u003d K.mean(inputs, axis\u003d1, keepdims\u003dTrue)\n        inputs \u003d K.l2_normalize(inputs, axis\u003d1)\n        pos \u003d K.relu(inputs)\n        neg \u003d K.relu(-inputs)\n        return K.concatenate([pos, neg], axis\u003d1)\n\n# global parameters\nbatch_size \u003d 128\nnum_classes \u003d 10\nepochs \u003d 5\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) \u003d mnist.load_data()\n\nx_train \u003d x_train.reshape(60000, 784)\nx_test \u003d x_test.reshape(10000, 784)\nx_train \u003d x_train.astype(\u0027float32\u0027)\nx_test \u003d x_test.astype(\u0027float32\u0027)\nx_train /\u003d 255\nx_test /\u003d 255\nprint(x_train.shape[0], \u0027train samples\u0027)\nprint(x_test.shape[0], \u0027test samples\u0027)\n\n# convert class vectors to binary class matrices\ny_train \u003d keras.utils.to_categorical(y_train, num_classes)\ny_test \u003d keras.utils.to_categorical(y_test, num_classes)\n\n# build the model\nmodel \u003d Sequential()\nmodel.add(layers.Dense(256, input_shape\u003d(784,)))\nmodel.add(Antirectifier())\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(256))\nmodel.add(Antirectifier())\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(num_classes))\nmodel.add(layers.Activation(\u0027softmax\u0027))\n\n# compile the model\nmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n              optimizer\u003d\u0027rmsprop\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\n\n# train the model\nmodel.fit(x_train, y_train,\n          batch_size\u003dbatch_size,\n          epochs\u003depochs,\n          verbose\u003d1,\n          validation_data\u003d(x_test, y_test))\n\n# next, compare with an equivalent network\n# with2x bigger Dense layers and ReLU",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:23:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "paragraphProgress": {
        "jobs": [],
        "numCompletedTasks": 0,
        "numTasks": 0,
        "truncated": false
      },
      "version": "v0",
      "jobName": "paragraph_1516016983929_-82724363",
      "id": "20180115-114943_529899946_q_ZGTJCVWT3Z1516357240",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "60000 train samples\n10000 test samples\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/5\n\n  128/60000 [..............................] - ETA: 2s - loss: 2.3062 - acc: 0.0938\n\n 2432/60000 [\u003e.............................] - ETA: 1s - loss: 1.9295 - acc: 0.6760\n\n 4736/60000 [\u003d\u003e............................] - ETA: 1s - loss: 1.7734 - acc: 0.7483\n\n 7040/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 1.6506 - acc: 0.7905\n\n 9344/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 1.5514 - acc: 0.8123\n\n11648/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 1.4609 - acc: 0.8293\n\n13952/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 1.3741 - acc: 0.8443\n\n16256/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 0s - loss: 1.2979 - acc: 0.8535\n\n18560/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 1.2274 - acc: 0.8609\n\n20864/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 1.1623 - acc: 0.8671\n\n23168/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 1.1039 - acc: 0.8728\n\n25472/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 1.0500 - acc: 0.8774\n\n27776/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 1.0006 - acc: 0.8817\n\n30080/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.9556 - acc: 0.8854\n\n32384/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.9144 - acc: 0.8886\n\n34688/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.8761 - acc: 0.8917\n\n36992/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.8410 - acc: 0.8947\n\n39296/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.8082 - acc: 0.8973\n\n41600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.7776 - acc: 0.8999\n\n43904/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.7502 - acc: 0.9022\n\n46208/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.7239 - acc: 0.9049\n\n48512/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.7002 - acc: 0.9070\n\n50816/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.6781 - acc: 0.9086\n\n53120/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.6571 - acc: 0.9106\n\n55424/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.6380 - acc: 0.9123\n\n57728/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.6200 - acc: 0.9141\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 25us/step - loss: 0.6034 - acc: 0.9157 - val_loss: 0.1512 - val_acc: 0.9627\n\nEpoch 2/5\n\n  128/60000 [..............................] - ETA: 2s - loss: 0.2254 - acc: 0.9531\n\n 2432/60000 [\u003e.............................] - ETA: 1s - loss: 0.1602 - acc: 0.9572\n\n 4736/60000 [\u003d\u003e............................] - ETA: 1s - loss: 0.1614 - acc: 0.9586\n\n 7040/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.1575 - acc: 0.9598\n\n 9344/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.1565 - acc: 0.9590\n\n11648/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.1565 - acc: 0.9578\n\n13952/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.1530 - acc: 0.9596\n\n16256/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 0s - loss: 0.1487 - acc: 0.9607\n\n18560/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.1472 - acc: 0.9609\n\n20864/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.1446 - acc: 0.9615\n\n23168/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.1423 - acc: 0.9621\n\n25472/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.1403 - acc: 0.9629\n\n27776/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.1374 - acc: 0.9636\n\n30080/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.1367 - acc: 0.9635\n\n32384/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.1352 - acc: 0.9638\n\n34688/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.1337 - acc: 0.9642\n\n36992/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.1341 - acc: 0.9641\n\n39296/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.1334 - acc: 0.9642\n\n41600/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.1323 - acc: 0.9643\n\n43904/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.1318 - acc: 0.9645\n\n46208/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.1306 - acc: 0.9648\n\n48512/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.1292 - acc: 0.9649\n\n50816/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.1282 - acc: 0.9651\n\n53120/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.1275 - acc: 0.9652\n\n55424/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.1271 - acc: 0.9652\n\n57728/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.1261 - acc: 0.9654\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 24us/step - loss: 0.1246 - acc: 0.9658 - val_loss: 0.1046 - val_acc: 0.9703\n\nEpoch 3/5\n\n  128/60000 [..............................] - ETA: 2s - loss: 0.1276 - acc: 0.9609\n\n 2432/60000 [\u003e.............................] - ETA: 1s - loss: 0.0873 - acc: 0.9729\n\n 4736/60000 [\u003d\u003e............................] - ETA: 1s - loss: 0.0817 - acc: 0.9753\n\n 7040/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0830 - acc: 0.9761\n\n 9344/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0806 - acc: 0.9777\n\n11648/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0786 - acc: 0.9779\n\n13952/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0816 - acc: 0.9770\n\n16256/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 0s - loss: 0.0821 - acc: 0.9768\n\n18432/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0822 - acc: 0.9768\n\n20736/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0814 - acc: 0.9770\n\n23040/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0822 - acc: 0.9771\n\n25344/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0818 - acc: 0.9772\n\n27648/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0817 - acc: 0.9774\n\n29952/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0817 - acc: 0.9772\n\n32256/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0823 - acc: 0.9769\n\n34560/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0819 - acc: 0.9768\n\n36864/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0821 - acc: 0.9768\n\n39168/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0828 - acc: 0.9766\n\n41472/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0830 - acc: 0.9764\n\n43776/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0828 - acc: 0.9764\n\n46080/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0828 - acc: 0.9764\n\n48384/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0820 - acc: 0.9767\n\n50688/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0814 - acc: 0.9769\n\n52864/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0814 - acc: 0.9770\n\n55040/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0825 - acc: 0.9767\n\n57344/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0824 - acc: 0.9767\n\n59648/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0826 - acc: 0.9764\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 25us/step - loss: 0.0825 - acc: 0.9765 - val_loss: 0.0875 - val_acc: 0.9753\n\nEpoch 4/5\n\n  128/60000 [..............................] - ETA: 2s - loss: 0.0457 - acc: 0.9844\n\n 2432/60000 [\u003e.............................] - ETA: 1s - loss: 0.0522 - acc: 0.9868\n\n 4736/60000 [\u003d\u003e............................] - ETA: 1s - loss: 0.0587 - acc: 0.9844\n\n 7040/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0614 - acc: 0.9837\n\n 9344/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0632 - acc: 0.9824\n\n11648/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0631 - acc: 0.9821\n\n13952/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0633 - acc: 0.9826\n\n16256/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......................] - ETA: 0s - loss: 0.0636 - acc: 0.9825\n\n18560/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0650 - acc: 0.9816\n\n20864/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0647 - acc: 0.9815\n\n23168/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0651 - acc: 0.9816\n\n25472/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0637 - acc: 0.9818\n\n27776/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0635 - acc: 0.9816\n\n30080/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0643 - acc: 0.9814\n\n32384/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..............] - ETA: 0s - loss: 0.0639 - acc: 0.9816\n\n34688/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0644 - acc: 0.9815\n\n36992/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0647 - acc: 0.9813\n\n39168/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0649 - acc: 0.9812\n\n41472/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0645 - acc: 0.9812\n\n43776/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0642 - acc: 0.9812\n\n46080/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......] - ETA: 0s - loss: 0.0642 - acc: 0.9812\n\n48384/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0637 - acc: 0.9813\n\n50560/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0636 - acc: 0.9814\n\n52864/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0638 - acc: 0.9813\n\n54656/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0642 - acc: 0.9811\n\n56832/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0639 - acc: 0.9812\n\n59008/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0639 - acc: 0.9812\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 25us/step - loss: 0.0638 - acc: 0.9812 - val_loss: 0.0703 - val_acc: 0.9781\n\nEpoch 5/5\n\n  128/60000 [..............................] - ETA: 2s - loss: 0.0183 - acc: 0.9922\n\n 2304/60000 [\u003e.............................] - ETA: 1s - loss: 0.0517 - acc: 0.9844\n\n 4608/60000 [\u003d\u003e............................] - ETA: 1s - loss: 0.0461 - acc: 0.9863\n\n 6656/60000 [\u003d\u003d\u003e...........................] - ETA: 1s - loss: 0.0537 - acc: 0.9853\n\n 8960/60000 [\u003d\u003d\u003d\u003e..........................] - ETA: 1s - loss: 0.0496 - acc: 0.9865\n\n11264/60000 [\u003d\u003d\u003d\u003d\u003e.........................] - ETA: 1s - loss: 0.0485 - acc: 0.9867\n\n13440/60000 [\u003d\u003d\u003d\u003d\u003d\u003e........................] - ETA: 1s - loss: 0.0467 - acc: 0.9874\n\n15744/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003e.......................] - ETA: 1s - loss: 0.0457 - acc: 0.9874\n\n18048/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....................] - ETA: 0s - loss: 0.0456 - acc: 0.9871\n\n20352/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....................] - ETA: 0s - loss: 0.0456 - acc: 0.9871\n\n22656/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...................] - ETA: 0s - loss: 0.0469 - acc: 0.9867\n\n24960/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..................] - ETA: 0s - loss: 0.0470 - acc: 0.9869\n\n27264/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.................] - ETA: 0s - loss: 0.0482 - acc: 0.9863\n\n29568/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e................] - ETA: 0s - loss: 0.0479 - acc: 0.9863\n\n31872/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...............] - ETA: 0s - loss: 0.0480 - acc: 0.9863\n\n34176/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.............] - ETA: 0s - loss: 0.0486 - acc: 0.9860\n\n36480/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e............] - ETA: 0s - loss: 0.0492 - acc: 0.9857\n\n38784/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...........] - ETA: 0s - loss: 0.0495 - acc: 0.9855\n\n41088/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..........] - ETA: 0s - loss: 0.0500 - acc: 0.9854\n\n43392/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.........] - ETA: 0s - loss: 0.0508 - acc: 0.9851\n\n45696/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e........] - ETA: 0s - loss: 0.0503 - acc: 0.9853\n\n48000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e......] - ETA: 0s - loss: 0.0501 - acc: 0.9853\n\n50304/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.....] - ETA: 0s - loss: 0.0507 - acc: 0.9851\n\n52608/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e....] - ETA: 0s - loss: 0.0508 - acc: 0.9849\n\n54784/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s - loss: 0.0506 - acc: 0.9849\n\n57088/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e..] - ETA: 0s - loss: 0.0509 - acc: 0.9848\n\n59392/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e.] - ETA: 0s - loss: 0.0511 - acc: 0.9846\n\n60000/60000 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 25us/step - loss: 0.0511 - acc: 0.9846 - val_loss: 0.0744 - val_acc: 0.9765\n\n\u003ckeras.callbacks.History object at 0x7ff4ea6974a8\u003e\n"
      },
      "dateCreated": "Jan 15, 2018 11:49:43 AM",
      "dateStarted": "Jan 22, 2018 5:23:14 AM",
      "dateFinished": "Jan 22, 2018 5:23:26 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Creating custom activation layer which modifies the shape of the tensor that passes through it. Using primitives from Keras.backend() so that it is compatible with both tensorflow and Theano.\nInput :- MNIST dataset. The MNIST dataset contains 60000 training images of 28x28 size and 10000 testing greyscale images of 28x28 size.\n    \n    The dataset is divided into one training batch with 60000 images and one test batch with 10000 images.\n    \n    Each batch contains a dictionary with the following elements:-\n    \n    data -- a 60000x28x28 numpy array of uint8s in case of training sample and 10000x28x28 numpy array of uint8s in case of testing sample. The first dimension of the array \n    marks the image number and the other dimensions is for the image matrix.\n    labels -- a list of 60000 numbers which are either 0 or 1 for training sample and 10000 numbers  for testing sample. The number at index i indicates the label of the ith     image in the array data.\n    \nOutput :- Accuracy of character recognition system. Real number between 0-1.",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:23:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": false,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516017003923_2057679741",
      "id": "20180115-115003_1926279887_q_ZGTJCVWT3Z1516357240",
      "dateCreated": "Jan 15, 2018 11:50:03 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "prashantp@qubole.com",
      "dateUpdated": "Jan 22, 2018 5:23:14 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "version": "v0",
      "jobName": "paragraph_1516360632927_-1761423148",
      "id": "20180119-111712_9231731_q_ZGTJCVWT3Z1516357240",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jan 19, 2018 11:17:12 AM",
      "dateStarted": "Jan 22, 2018 5:23:14 AM",
      "dateFinished": "Jan 22, 2018 5:23:26 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "antirectifier_custom_layer_mnist",
  "id": "ZGTJCVWT3Z1516357240",
  "angularObjects": {
    "2D7M1HZP5932661518613479637:shared_process": [],
    "2D6B43M8G932661515762929145:shared_process": [],
    "2D35KXZZK932661515762929137:shared_process": []
  },
  "config": {
    "isDashboard": false
  },
  "info": {},
  "source": "FCN"
}